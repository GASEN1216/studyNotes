
矩阵计算
====

标量导数
----

![](https://img-blog.csdnimg.cn/98af80fcfc6b4c0e97681dd575ab0658.png)

亚导数
---

比如 y=|x | 的导数，可以在 [-1,1] 之间取任意值  
![](https://img-blog.csdnimg.cn/f81226938e2347dab9630c354a3fb465.png)

梯度
--

将**导数拓展到向量** -> 梯度  
![](https://img-blog.csdnimg.cn/11390cbf19c84d009beec2d671650d92.png)  
**第一种情况：y 标量 x 向量**

1.  标量关于列向量的导数是一个行向量
2.  **梯度和等高线是正交的**，意味着是梯度指向的是你的**值变化最大的地方**

![](https://img-blog.csdnimg.cn/ce810093c37e46f7970eae0e9f881981.png)

![](https://img-blog.csdnimg.cn/1c8ec57718964ee9936525d4f969245c.png)  
（y 标量 x 向量）

补充：内积  
![](https://img-blog.csdnimg.cn/d4e1b1e8664a4a5ba25352a6f6ac78d7.png)  
可以这样来理解向量内积：

向量 a、b 的内积等于向量 a 在 b 方向的分量（或投影）与 b 的内积，当 a、b 垂直时，a 在 b 方向上无分量，所以内积为 0。

其他几何意义：从**内积数值**上我们可以看出**两个向量的在方向上的接近程度**。  
当内积值为正值时，两个向量大致指向相同的方向（方向夹角小于 90 度）；  
当内积值为负值时，两个向量大致指向相反的方向（方向角大于 90 度）；  
当内积值为 0 时，两个向量互相垂直  
**第二种情况：x 标量 y 向量**  
![](https://img-blog.csdnimg.cn/8cd4af10b11a49efa2b06ad400f5d597.png)  
**第二种情况：x 向量 y 向量**

![](https://img-blog.csdnimg.cn/671e258f99ab42fa90b4bc6f21e84a40.png)

![](https://img-blog.csdnimg.cn/6063344328704785a596ab24bcdcaf8a.png)  
![](https://img-blog.csdnimg.cn/a61b2485a85341e7bf69af56c0b072b0.png)  
机器学习只关心 NP 问题，所以基本上找不到最优解

自动求导
====

向量链式求导法则
--------

![](https://img-blog.csdnimg.cn/e3fe3f2d8a3f486783ebd6fb1e0dcf7d.png)  
![](https://img-blog.csdnimg.cn/32f69fe42aea40299d3beb7ad6d19b33.png)![](https://img-blog.csdnimg.cn/4a465918bf88453db00c51aee1bfbc74.png)![](https://img-blog.csdnimg.cn/2c991299f2594f83b85b4573d91cfc07.png)

自动求导
----

![](https://img-blog.csdnimg.cn/357f3eb9aa1044d7af251c3a1b4cef42.png)  
![](https://img-blog.csdnimg.cn/1c0401db5b284486943492788ecdf60f.png)  
计算图其实等价于链式求导 过程  
![](https://img-blog.csdnimg.cn/0c808a65bcce472fa98da6a48855ad5a.png)

显示构造就是数学上的那种

![](https://img-blog.csdnimg.cn/c55221d016e544968dda50ca8d7ee6b3.png)  
![](https://img-blog.csdnimg.cn/b840b082bd724b1787169b06fa006de2.png)  
![](https://img-blog.csdnimg.cn/6d0841b6d9f44d7dbfede1991fb5aa4b.png)![](https://img-blog.csdnimg.cn/cc123d407dfb41a3ac9f7658df8561d7.png)

复杂度
---

假设神经网络有 n 层（n 个操作子）  
内存：神经网络耗费 GPU 资源的最大原因  
![](https://img-blog.csdnimg.cn/363f60b9e4304f079d5bac00cf9281fc.png)

自动求导实现
------

![](https://img-blog.csdnimg.cn/d4881f1f359643c0bf5cf1b2a2211434.png)  
![](https://img-blog.csdnimg.cn/fa7b8228bc4e446eb8760c30841e2b6b.png)![](https://img-blog.csdnimg.cn/e9f2d39bed584e1299d2ca72b5bc11c1.png)  
![](https://img-blog.csdnimg.cn/d9bc7292c7bb4c50bf05ccfda82cf255.png)

![](https://img-blog.csdnimg.cn/31dd6644529944d097e0a88f90876c31.png)  
loss 通常是一个标量，向量对于一个矩阵的 loss 就会变成矩阵，矩阵再往下走就变成一个 4 维矩阵，神经网络一深就变成一个特别大的张量

![](https://img-blog.csdnimg.cn/7bb531c5b0644fafaaf8a365c8a6ca13.png)  
是的

softmax 回归 + 损失函数
=================

softmax 回归
----------

![](https://img-blog.csdnimg.cn/67892b26d84e4e6fa9a1f8b468d5029f.png)  
![](https://img-blog.csdnimg.cn/ab40c87e615d48d7b071ca9c63a55581.png)![](https://img-blog.csdnimg.cn/989ac2abba5e4d13897ab758fabca6ca.png)  
![](https://img-blog.csdnimg.cn/d62c1a3ba67541e886079103839668e5.png)  
我们需要对正确类别的置信度 o_y 特别大

![](https://img-blog.csdnimg.cn/054cf01d19bf4d6e885fa5b0af038763.png)  
![](https://img-blog.csdnimg.cn/7988ff1e7cb0446189f4943bda09b910.png)  
可以看到，对于分类问题来讲，我们不关心对于非正确类的预测值，我们只关心正确类的置信度有多大  
![](https://img-blog.csdnimg.cn/3b4c7be0dedb467d9b4d229567374847.png)

损失函数
----

![](https://img-blog.csdnimg.cn/96d93905f3e842f5a433fbd1271e411a.png)

1.  二次损失函数的倒数（线性）决定了我们是如何更新我们的参数的
2.  **最小化损失函数等价于最大化似然函数**  
    ![](https://img-blog.csdnimg.cn/6acdfafd502f413aaabd8b7fa7bec096.png)

L1 损失函数的导数是说，不管我的预测值和真实值离得多远权重更新也不会特别大，**带来稳定性上的好处**。但是 0 点处 - 1 到 1 之间的剧烈变化，这个不平滑性导致当预测值靠得近的时候，也就是优化到末期的时候这个地方就不那么稳定了

可以提出一个新的函数来组合两者，  
![](https://img-blog.csdnimg.cn/0ccc42dc324645c6bff7e8ba4756396e.png)![](https://img-blog.csdnimg.cn/9e0a27d943f940df9e4c0465129a630a.png)

QA
--

![](https://img-blog.csdnimg.cn/2411a7abd04841faa3c71894c5fa894c.png)  
onehot 正确为 1 剩余为 0，用 softmax 逼近纯 0-1 的分布，问题是很难用指数逼近 1，因为指数变成 1 要求输出几乎接近于无穷大，所以用 softlabel（0.1-0.9）真的用 softmax 去拟合那些 0.9 是可能的

权重衰退
====

![](https://img-blog.csdnimg.cn/f37b46b8089742bd98729fb935cb6310.png)

怎么控制一个模型的容量？一个是我把模型控制的比较小，参数比较少，第二个是使得每个参数的值的范围比较小，权重衰退就是通过控制整个值的选择范围来进行的  
![](https://img-blog.csdnimg.cn/9fd32c41eb774a7d91948c9275e8b95b.png)  
![](https://img-blog.csdnimg.cn/92b9054aa82c422dba81b715326cd77b.png)  
**惩罚项的引入使得我的最优解往原点走了，最优解的值变小，模型的复杂度变低了**

**正则化如何让权重衰退？**

![](https://img-blog.csdnimg.cn/e10be81492074e3fbe7665daf4a65c53.png)  
因为 lamda 的引入，每次更新前我们先把我们的权重做了一次放小

![](https://img-blog.csdnimg.cn/20cc4380387b4a0d86d1451ebbebc88b.png)![](https://img-blog.csdnimg.cn/504f12789e0b4262b23a8990878a2528.png)  
![](https://img-blog.csdnimg.cn/fb0fd71b22fb4720a6e62d03a17239fe.png)  
因为数据有噪音，你学到的参数可能特别大，因为我们的算法看到的是噪音，只要模型允许的话他不断试图去选一个权重记住我所有的样本，那就会尝试记住噪音，记住那些抖动的东西，他就会学到一个特别大的地方

丢弃法 Dropout
===========

![](https://img-blog.csdnimg.cn/9a7646a3c58e459c9d96ffdddffe7de0.png)![](https://img-blog.csdnimg.cn/df16c0338c3e4a419a1bad8f9806773f.png)

1.  正则就是防止你的权重比较大，是一个避免过拟合的方法
2.  在数据里面加入噪音等价于一个正则，之前在数据里加噪音，这里是一个随机加噪音
3.  丢弃法 Dropout 是在输入加噪音，在层也加噪音  
    ![](https://img-blog.csdnimg.cn/85dc5d4ab0444154b615d85c22e20bee.png)![](https://img-blog.csdnimg.cn/60b5b342f4c244a19348ea184e1fec8b.png)  
    保证均值 / 期望不会变  
    ![](https://img-blog.csdnimg.cn/873eb94daa024ac9a4fe491838b605e5.png)![](https://img-blog.csdnimg.cn/afdef16c551d48ac83272a0ae7f0a2dd.png)  
    dropout 只会对你的权重产生影响，在预测的时候权重都不需要发生变化的时候我们是不需要正则的  
    ![](https://img-blog.csdnimg.cn/2a6e8903c222431db9c9cd85e1538871.png)  
    没有理论依据，实验效果上和正则（主流）一样  
    ![](https://img-blog.csdnimg.cn/9b4dbc8a290a4fff8f91b9390416b535.png)

从零开始实现 dropout
--------------

```
import torch
from torch import nn 
from d2l import torch as d2l
import torchvision
from torchvision import transforms
from torch.utils import data

def dropout_layer(X,dropout):
    assert 0<=dropout <= 1
    # 如果dropout概设置为1，全部元素被丢弃
    if dropout == 1:
        return torch.zeros_like(X)
    # 如果dropout概设置为0，全部元素被保留
    if dropout == 0:
        return X
    mask = (torch.rand(X.shape)>dropout).float() #使用mask而不是直接置零是为了提高计算效率
    return mask *X/(1.0-dropout)


```

```
# 测试dropout layer层
X = torch.arange(16,dtype=torch.float32).reshape((2,8))
print(X)
print(dropout_layer(X,0))
print(dropout_layer(X,0.5))
print(dropout_layer(X,1))


```

测试 Dropout 的结果：

![](https://img-blog.csdnimg.cn/045c80695860477f9bbe33fa9269351b.png)  
![](https://img-blog.csdnimg.cn/753d2f16049f40beab0015e9afdc49a4.png)

BN 用在卷积，Dropout 用在全连接层  
![](https://img-blog.csdnimg.cn/8b7414eb2d414a1394e9ae242d77325c.png)  
是的

数值稳定性 + 模型初始化和激活函数
==================

数值稳定性——梯度消失和梯度爆炸
----------------

![](https://img-blog.csdnimg.cn/2e79821d2e0d41feb5b68373a9b0786d.png)  
注：1. y 在这里不是预测，还包括了损失函数  
2. 这里的 h 都是向量，**向量关于向量的导数是矩阵，是矩阵乘法，所以我们的主要问题也是来自这个地方，因为我们做了太多的矩阵乘法**  
![](https://img-blog.csdnimg.cn/a8e8f7e2868b4354bd2a6bd8033b212e.png)![](https://img-blog.csdnimg.cn/13fb67a5c2414d78860556e1c18ebbc5.png)  
delta 是一个按元素的函数，所以他的求导就变成一个对角矩阵

### 梯度爆炸

![](https://img-blog.csdnimg.cn/17f4d4cdca73472ca15b265a0ddae6c0.png)  
relu 作为激活函数求导，相当于吧某一列留住了或者变为 0; 假设 w_i 的值非常大（大于 1）的话，那么最后会有非常大的值，发生梯度爆炸  
![](https://img-blog.csdnimg.cn/32132542e54a441abdb624b4918f2147.png)  
3. **学习率太大，因为我们一步走的比较远，对权重的更新权重变得比较大**，我们的**梯度就是权重的乘法**，更大的梯度，那就会带来更大的参数值。。。  
4. 也不算是完全没法训练，就是调学习率变得很难调，学习率只有一个很小的范围内是好的

### 梯度消失

![](https://img-blog.csdnimg.cn/b8ddfab4ae824fbca539b2de902b12e0.png)![](https://img-blog.csdnimg.cn/48d00aa62c22441c892e7b49bbee0870.png)![](https://img-blog.csdnimg.cn/9e8f9719a91a4f54b6c06811d3b15974.png)  
![](https://img-blog.csdnimg.cn/0d010b27b25f46d3945862a8f495b922.png)  
你的梯度其实就是对 n 个层做累乘，如果你的值比较小或者激活函数使得你的值变得比较小。。。

### 如何让训练更加稳定？

![](https://img-blog.csdnimg.cn/5dd19ec2005749bba2351cb3dd65f887.png)  
如果你的时序序列很长的话，比如是 100，输入一个时序为 100 的句子，  
**原始的 RNN 就是对这 100 个时序做乘法。LSTM 吧这些乘法变成加法，吧 100 次乘法变成 100 次加法**

### 梯度消失和梯度爆炸的产生原因和解决办法？

什么是梯度消失和梯度爆炸

在**反向传播**过程中需要**对激活函数进行求导**，如果导数大于 1，那么随着网络层数的增加**梯度更新**将会朝着**指数爆炸**的方式增加这就是梯度爆炸。同样如果导数小于 1，那么随着网络层数的增加**梯度更新**信息会朝着**指数衰减**的方式减少这就是**梯度消失**。因此，梯度消失、爆炸，其**根本原因在于反向传播训练法则**，属于先天不足。

梯度消失、爆炸导致原因

1.  **从 BP（反向传播原理）解释梯度消失和梯度爆炸**
2.  从激活函数角度分析梯度消失  
    如果激活函数选择不合适，比如使用 sigmoid，梯度消失就会很明显了，原因看下图，左图是 sigmoid 的损失函数图，右边是其导数的图像，如果使用 sigmoid 作为损失函数，其梯度是不可能超过 0.25 的，这样经过链式求导之后，很容易发生梯度消失，sigmoid 函数数学表达式为：  
    ![](https://img-blog.csdnimg.cn/ba6305b3f3b34db9b6733f1f16861d73.png)![](https://img-blog.csdnimg.cn/9d6fb12699b748f189c6f0800eb77755.png)  
    同理，tanh 作为激活函数，它的导数图如下，可以看出，**tanh 比 sigmoid 要好一些，但是它的导数仍然是小于 1 的**。tanh 数学表达为：

![](https://img-blog.csdnimg.cn/2d4435b023ef4b7188a5617f88ff345d.png)

梯度消失、爆炸的解决方案

1.  预训练加微调  
    为了**解决梯度的问题**，采取无监督逐层训练方法，其基本思想是每次训练一层隐节点，训练时将上一层隐节点的输出作为输入，而本层隐节点的输出作为下一层隐节点的输入，此过程是逐层 “预训练”（pre-training）；在预训练完成后，再对整个网络进行 “微调”（fine-tunning）。此思想相当于是先寻找**局部最优**，然后**整合起来寻找全局最优**，此方法有一定的好处，但是目前应用的不是很多了。
2.  **梯度剪切及正则化解决梯度爆炸**  
    梯度剪切这个方案主要是针对梯度爆炸提出的，其思想是设置一个梯度剪切阈值，然后更新梯度的时候，如果梯度超过这个阈值，那么就将其强制限制在这个范围之内。这可以防止梯度爆炸。

另外一种解决梯度爆炸的手段是采用权重正则化（weithts regularization）。

正则化是通过对网络权重做正则限制过拟合，仔细看正则项在损失函数的形式：

![](https://img-blog.csdnimg.cn/ce33b5647fef4ebfbc0f1eaff5558b14.png)  
其中， alpha 是指正则项系数，因此，如果发生梯度爆炸，权值的范数就会变的非常大，通过正则化项，可以部分限制梯度爆炸的发生。**但在深度模型中，梯度消失更常见一些。**

3.  relu、leakrelu、elu 等激活函数  
    ![](https://img-blog.csdnimg.cn/e915ebcecbaf417ebe2dba72008657e5.png)![](https://img-blog.csdnimg.cn/52e9c2b0b6c94df6a42cf1b138227a39.png)
    
4.  batch normalization  
    Batchnorm 是深度学习发展以来提出的最重要的成果之一了，目前已经被广泛的应用到了各大网络中，具有加速网络收敛速度，提升训练稳定性的效果，Batchnorm 本质上是解决反向传播过程中的梯度问题。batchnorm 全名是 batch normalization，简称 BN，即批规范化，通过规范化操作将输出信号 x 规范化到均值为 0，方差为 1 保证网络的稳定性。  
    batchnorm 就是通过对每一层的输出规范为均值和方差一致的方法，消除了 x 带来的放大缩小的影响，进而解决梯度消失和爆炸的问题。
    
5.  残差学习和 LSTM
    

模型初始化和激活函数
----------

![](https://img-blog.csdnimg.cn/d002439b2df84274b5e5c6f4c9acb20f.png)  
不管你的网络有多深，最后一层和第一层都差不多，都是均值为 0 方差为某个特定值，我希望我的**输出和梯度都在这个区间里面**

![](https://img-blog.csdnimg.cn/1ce25f1a043a4595a92e6d6a3738d7de.png)

1.  因为在训练开始的时候更容易有数值不稳定，；比如初始的时候梯度比较大，可能 W 变得更加大，然后出问题
    
2.  **随机初始化参数有什么问题？**  
    随机初始化**没有控制方差**，所以对于**深层网络**而言，随机初始化方法依然可能失效。  
    理想的参数初始化还得控制方差，对 w 进行一个规范化
    

![](https://img-blog.csdnimg.cn/db33dd7d91734e43838faf354048b74d.png)  
![](https://img-blog.csdnimg.cn/cd8d89a0b6d24c909e1cfdcc8314ea4f.png)  
![](https://img-blog.csdnimg.cn/1c9500198ece4dd896b98b74f19ee5be.png)![](https://img-blog.csdnimg.cn/6f6664627bf2460bb5cad48c792d93fc.png)  
nt-1 是输入的维度，nt 是输出的维度，除非输入刚好等于输出，否则无法同时满足这两个条件

![](https://img-blog.csdnimg.cn/1647d3237b5243ce896ba8fa8ebdfce1.png)  
为了使得我的前向输出都是均值为 0 方差为 1，激活函数必须等于本身  
![](https://img-blog.csdnimg.cn/9d2935a9c93449fbafb7d25608567b36.png)  
反向也一样  
![](https://img-blog.csdnimg.cn/031f3eceb5a4433bbb46bcd27024099a.png)  
![](https://img-blog.csdnimg.cn/e37aff86c6354f16b6956766eedd6427.png)  
具体来说，我们每一层的输出和每一层的梯度都是均值为 0 方差为固定数的随机变量，权重初始化选用 Xavier，激活函数选用 relu 或者 tanh 都没有太大问题，sigmoid 可以做一下变换

![](https://img-blog.csdnimg.cn/73c796bbc1ec4486ab6b4b014c0b828f.png)

1.  inf 就是太大了，一般都是学习率太大或者权重初始的值太大了
2.  NaN 一般就是一个数除以 0 了
3.  解决的话就是合理的初始化权重，激活函数不要选错，学习率不要太大。如果碰到这个问题，最简单的做法就是吧学习率调到比较小，直到 inf 或者 NAN 不再出现，第二就是看一下权重的初始，方差小一点  
    ![](https://img-blog.csdnimg.cn/e3fdbe195abb4a32a62a6ee5c23e282c.png)

![](https://img-blog.csdnimg.cn/c27a266a509a45cfa7758d70ab0abf39.png)  
是的，一般 NAN 就是梯度太大造成的，如果太小就不会有什么进展 train 不动  
![](https://img-blog.csdnimg.cn/f9bae65e83164fd491e2462f94abd180.png)

### 深度神经网络权值初始化的几种方式及为什么不能初始化为零

[深度神经网络权值初始化的几种方式及为什么不能初始化为零](https://cloud.tencent.com/developer/article/1688031)

在深度学习中，神经网络的权重初始化方式非常重要，其对模型的收敛速度和性能有着较大的影响。一个好的权值初始值有以下优点：

· **梯度下降的收敛速度较快**

· 深度神经中的网络模型不易陷入梯度消失或梯度爆炸问题

0 初始化

在**线性回归和逻辑回归中**，我们通常把权值 w 和偏差项 b 初始化为 0，并且我们的模型也能取得较好的效果。在线性回归和逻辑回归中，我们采用类似下面的代码将权值初始化为 0（tensorflow 框架下）：

```
w = tf.Variable([[0,0,0]],dtype=tf.float32,name='weights') 
b = tf.Variable(0,dtype=tf.float32,name='bias')

```

**但是，当在神经网络中的权值全部都使用 0 初始化时，模型无法正常工作了。**

**原因是**：在**神经网络中因为存在隐含层**。我们假设模型的输入为 [x1,x2,x3]，隐含层数为 1，隐含层单元数为 2，输出为 y

模型如下图所示：  
![](https://img-blog.csdnimg.cn/43f888a205af4059934b85bef8dbb9c3.png)  
则通过正向传播计算之后，可得

```
z1 = w10 * x0 + w11 * x1 + w12 * x2 +w13 * x3
z2 = w20 * x0 + w21 * x1 + w22 * x2 +w23 * x3

```

在所有的权值 w 和偏差值 b （可以看做是 w10）初始化为 0 的情况下，即计算之后的：

z1 = 0，z2 = 0

那么由于

a1 = g(z1) 、a2 = g(z2)

**经过激活函数之后得到的 a1 和 a2 也肯定是相同的数了**

**即 a1 = a2 = g(z1)**

则输出层：y = g(w20 * a0 + w21 * a1 + w22 *a2)

**也是固定值了。**

重点：在反向传播过程中，我们使用梯度下降的方式来降低损失函数，但在更新权值的过程中，**代价函数对不同权值参数的偏导数相同 ，即 Δw 相同，因此在反向传播更新参数时：**

w21 = 0 + Δw

w22 = 0 + Δw

实际上使得更新之后的不同节点的参数相同，**同理可以得到其他更新之后的参数也都是相同的**，不管进行多少轮的正向传播和反向传播，得到的参数都一样！因此，神经网络就失去了其特征学习的能力。

**总结一下：在神经网络中，如果将权值初始化为 0 ，或者其他统一的常量，会导致后面的激活单元具有相同的值，所有的单元相同意味着它们都在计算同一特征，网络变得跟只有一个隐含层节点一样，这使得神经网络失去了学习不同特征的能力！**

### Xavier Initialization

**Xavier Initialization**

早期的参数初始化方法普遍是将数据和参数 normalize 为高斯分布（均值 0 方差 1），但随着神经网络深度的增加，这方法**并不能解决梯度消失问题**。

![](https://img-blog.csdnimg.cn/84277c677515421d99d698285cf24abb.png)  
Xavier 初始化的作者，Xavier Glorot，在 Understanding the difficulty of training deep feedforward neural networks 论文中提出一个洞见：**激活值的方差是逐层递减的，这导致反向传播中的梯度也逐层递减**。要**解决梯度消失**，就要**避免激活值方差的衰减**，最理想的情况是，**每层的输出值（激活值）保持高斯分布**。

**为什么我们首先需要初始化？**  
![](https://img-blog.csdnimg.cn/d0d2c8df2a3a4e9ba971b4028e3a1800.png)  
**Xavier 初始化到底是什么？**

在我们开始训练之前分配网络权重似乎是一个随机的过程，对吧？我们对数据一无所知，因此**我们不确定如何分配在该特定情况下有效的权重。**一个好方法是**从高斯分布中分配权重**。显然，这种分布的**均值为零**，并且**具有一些有限方差**。让我们考虑一个线性神经元：  
![](https://img-blog.csdnimg.cn/9f368191f6ed4dba9746fb2951b9a8fc.png)  
**对于每个传递层**，我们希望**方差保持不变**。这**有助于我们防止信号爆炸到高值或消失到零**。换句话说，我们需要以这样的方式初始化权重，即 x 和 y 的方差保持不变。此初始化过程称为 Xavier 初始化。

**如何执行 Xavier 初始化？**

![](https://img-blog.csdnimg.cn/d45de96cc3f0409b80b1664ed97bcf55.png)

![](https://img-blog.csdnimg.cn/b56b1efa0cfa489183b433a554c233f1.png)

### Kaiming Initialization

我们提到 Xavier 初始化方法适用的激活函数有限：**关于 0 对称；线性**。而 ReLU 激活函数并不满足这些条件，实验也可以验证 Xavier 初始化确实不适用于 ReLU 激活函数。  
![](https://img-blog.csdnimg.cn/288348100591406b85542dc7a639f3e0.png)  
Xavier 初始化**在 Relu 层表现不好**，主要原因是 **relu 层会将负数映射到 0**，影响整体方差。所以何恺明在对此做了改进提出 Kaiming 初始化，一开始主要应用于计算机视觉、卷积网络。

**在 ReLU 网络中，假定每一层有一半的神经元被激活，另一半为 0，所以，要保持方差不变，只需要在 Xavier 的基础上再除以 2  
也就是说在方差推到过程中，式子左侧除以 2.**

在 Xavier 论文中，作者给出的 Glorot 条件是：**正向传播时，激活值的方差保持不变；反向传播时，关于状态值的梯度的方差保持不变**。这在本文中稍作变换：正向传播时，状态值的方差保持不变；反向传播时，关于激活值的梯度的方差保持不变。

其中，激活值是激活函数输出的值，状态值是输入激活函数的值。

多层感知机
=====

感知机
---

从现在的观点来看，**感知机实际上就是神经网络中的一个神经单元**

1.  **w 与 x 算内积**
2.  感知机其实就是一个**二分类的问题**（1,0 问题当然也可以当成 1，-1 分类）  
    ![](https://img-blog.csdnimg.cn/9cfccf4cfb274b4789210ba1cbbcc4d1.png)  
    **感知机能解决二分类问题**，但与线性回归和 softmax 回归有所区别：线性回归与 softmax 回归的输出均为实数，softmax 回归的输出同时还满足概率公理。  
    ![](https://img-blog.csdnimg.cn/abede370f23b4660b9695bf0dba94469.png)![](https://img-blog.csdnimg.cn/89c5f4b75cdb49dfb14439a2ed595f08.png)  
    **线性模型的缺陷**

猫狗分类的例子：

直到猫狗都分类正确的时候会停止：  
![](https://img-blog.csdnimg.cn/b21085a42b6f4a279d26ff5e4ce07fc6.png)

**感知机有什么问题？**  
![](https://img-blog.csdnimg.cn/f5366b0493594052bbf1d06b3a20e5cb.png)

1.  **感知机是一个二分类模型，是最早的 AI 模型之一。**
2.  它的求解算法等价于使用批量大小为 1 的梯度下降。
3.  **它不能拟合 XOR 函数，这导致了第一次 AI 寒冬。**

多层感知机
-----

我们可以通过在网络中加入**一个或多个隐藏层**来**克服线性模型的限制**， 使其能处理更普遍的函数关系类型。 要做到这一点，最简单的方法是将许多全连接层堆叠在一起。 每一层都输出到上面的层，直到生成最后的输出。 **我们可以把前 L−1 层看作表示，把最后一层看作线性预测器**。 这种架构通常称为多层感知机（multilayer perceptron），通常缩写为 MLP。

**怎么解决 XOR 问题？**

1.  线性模型肯定是不行，我们可以分为几步来完成：第一步学出来蓝色的线，然后再学习一根黄色的线。有了蓝色和黄色分类器的结果，我们看两个结果是不是一样（正正得正），然后进入灰色分类器得到正确结果。
2.  仍以 XOR 问题为例，XOR 问题的一个解决思路是分类两次，先按 x 轴分类为 + 和 -，再按 y 轴分类为 + 和 -，最后将两个分类结果相乘，+ 即为一三象限，- 即为二四象限：
3.  蓝 黄 -》灰
4.  这实际上将信息进行了多层次的传递：

![](https://img-blog.csdnimg.cn/f24838ed858c4d92ae8a1637fdf282e1.png)  
有了 XOR 问题的解决经验，可以想到如果将多个感知机堆叠起来，形成具有多个层次的结构，如图：

![](https://img-blog.csdnimg.cn/23e40ceada414565a55d0b6523e092f6.png)  
这里的模型称为多层感知机，第一层圆圈称为输入 x1 x2 x3 x4 x5（实际上他并非感知机），之后的一层称为隐藏层，由 5 个感知机构成，他们均以前一层的信息作为输入，最后是输出层，以前一层隐藏层的结果作为输入。除了输入的信息和最后一层的感知机以外，其余的层均称为隐藏层，隐藏层的设置为模型一个重要的超参数，这里的模型有一个隐藏层。  
![](https://img-blog.csdnimg.cn/5e586416bbc6418fae2d1a685ab37e8f.png)  
**为什么需要激活函数？**

1.  假设没有激活函数的话，输出仍然是线性函数，多层感知机仍然是单层感知机
2.  但是仅仅有线性变换是不够的，如果我们简单的**将多个线性变换按层次叠加，由于线性变换的结果仍为线性变换，所以最终的结果等价于线性变换，与单个感知机并无区别**，反而加大了模型，浪费了资源，为了防止这个问题，需要对每个单元（感知机）的输出通过激活函数进行处理再交由下一层的感知机进行运算，这些激活函数就是解决非线性问题的关键。  
    ![](https://img-blog.csdnimg.cn/2748225e69ce441cbfcf471047e3e80d.png)

激活函数
----

激活函数（activation function）通过**计算加权和并加上偏置**来确定**神经元是否应该被激活**，它们将输入信号转换为输出的可微运算。大多数激活函数都是非线性的。  
![](https://img-blog.csdnimg.cn/0466150fabeb4c2f9b9c93a38448cc87.png)![](https://img-blog.csdnimg.cn/c4cd2a36a17042deb5b88df945618f47.png)  
**指数运算在 CPU 上是很贵的，sigmoid 和 tanh 都有指数运算（可能相当于一百次乘法运算的时间）**，GPU 上好一点但还是很贵，而 relu 没有  
![](https://img-blog.csdnimg.cn/e2cc89045fec4f6c9d051a3b5d003a06.png)

多类分类
----

![](https://img-blog.csdnimg.cn/7b08f82e2e8e49d0932dd733f2447d98.png)

![](https://img-blog.csdnimg.cn/1c4d31ea2c784b2297508314702285c6.png)  
**隐藏层先压缩再扩展可能会损失一些信息，再恢复就比较难了。卷积的话先压缩再扩展可以防止模型过拟合**  
![](https://img-blog.csdnimg.cn/66c034e87fea477dbb53b4c691fc396d.png)

从全连接到卷积
=======

![](https://img-blog.csdnimg.cn/27474ed755644dce8d4c9198058ea3c1.png)![](https://img-blog.csdnimg.cn/4ac796ac310d46dcba7d602cd66e8652.png)  
**图片跟之前的一维输入有什么不一样的地方？**

![](https://img-blog.csdnimg.cn/7d115dd6af574a3890fc03e3a6759103.png)  
参数共享和局部连接

卷积是一个特殊的（受限）的全连接层。

![](https://img-blog.csdnimg.cn/f5b0a4effa974d0d977b081cdb1a3bef.png)

1*1 卷积层
-------

![](https://img-blog.csdnimg.cn/54667245cefb4cd289fba512ce77bb73.png)  
![](https://img-blog.csdnimg.cn/6cd1c329acc04c1eba9fc757d72ac341.png)

池化层
===

检测边缘，假设卷积核 [1,-1],  
![](https://img-blog.csdnimg.cn/07588cdd7069442eb4241acc8ddd519f.png)  
**我们需要一定的平移不变性，物体稍微的改动不会太影响输出**  
卷积对位置太敏感不是一个太好的事情，所以需要池化层

最大池化层
-----

1.  **二维最大池化允许你的输入发生一定小小的偏移，使得你的卷积输出有一点模糊化 的效果，使得在输出的值的附近的一个小窗口里面值都会出现**
2.  有跟卷积类似的超参数：填充和步幅，但是没有可学习参数
3.  **不像卷积一样融合多输入通道，池化对每个通道做一次池化层**  
    ![](https://img-blog.csdnimg.cn/974da2f9e6ba485f9be840da8ac9cc5b.png)![](https://img-blog.csdnimg.cn/bc27bc5e51004e839458032458773ea6.png)

平均池化层
-----

![](https://img-blog.csdnimg.cn/380ec27ece704dae852211c8516ec9f6.png)  
![](https://img-blog.csdnimg.cn/702762f1551049a28af60f2707288a32.png)  
池化层对特征图进行压缩。1. 使特征图变小，简化网络计算复杂度，减少下一层的参数和计算量，防止过拟合；2. 进行特征压缩，提取特征，保留主要的特征；**保持某种不变性，包括平移**、（旋转？）和尺度，尺度不变性也就是增大了感受野。

缺点：但是**它在降维的过程中丢失了一些信息（因为毕竟它变小了嘛，只留下了它认为重要的信息）**，降低了分辨率。

卷积的 stride 也可以使得特征图变小

另外，**现在的数据增广操作一定程度上已经从数据层面上使得你的卷积不会过拟合到某一个位置，这就淡化了池化层的作用**  
[参考](https://zhuanlan.zhihu.com/p/88985074#:~:text=%E5%B9%B3%E7%A7%BB%E4%B8%8D%E5%8F%98%E6%80%A7%E6%98%AF%E6%8C%87%E8%BE%93%E5%87%BA%E7%BB%93%E6%9E%9C%E5%AF%B9%E8%BE%93%E5%85%A5%E7%9A%84%E5%B0%8F%E9%87%8F%E5%B9%B3%E7%A7%BB%E5%9F%BA%E6%9C%AC%E4%BF%9D%E6%8C%81%E4%B8%8D%E5%8F%98%E3%80%82%20%E4%BE%8B%E5%A6%82%E8%BE%93%E5%85%A5%E4%B8%BA,%281,5,3%29%EF%BC%8C%E6%9C%80%E5%A4%A7%E6%B1%A0%E5%8C%96%E5%B0%86%E4%BC%9A%E5%8F%965%EF%BC%8C%E5%A6%82%E6%9E%9C%E5%B0%86%E8%BE%93%E5%85%A5%E5%8F%B3%E7%A7%BB%E4%B8%80%E4%BD%8D%E5%BE%97%E5%88%B0%20%280,1,5%29%EF%BC%8C%E8%BE%93%E5%87%BA%E7%9A%84%E7%BB%93%E6%9E%9C%E4%BB%8D%E4%B8%BA5%E3%80%82)

LeNet
=====

1. 手写数字识别
---------

1.  LeNet 网络最早是为了应用于**手写数字的识别**应用。
2.  应用背景：  
    邮政局希望可以自动读出信件上的邮政编码  
    人们希望可以用支票自动取钱
3.  该模型在 80 年代末的银行被真正的部署

![](https://img-blog.csdnimg.cn/0ef9e014deca415385826c1709cd5951.png)

2. MNIST
--------

1.  LeNet 所使用的数据集
2.  50，000 个训练数据
3.  10，000 个测试数据
4.  图像大小为 28*28
5.  10 类  
    ![](https://img-blog.csdnimg.cn/f0f6f89470fc4b6c8eb1362281653612.png)

3.LeNet 的具体模型
-------------

1.  LeNet-5 是一个较简单的卷积神经网络。下图显示了其结构：输入的二维图像，先经过两次卷积层到池化层，再经过全连接层，最后使用 softmax 分类作为输出层
2.  LeNet-5 这个网络虽然很小，但是它包含了深度学习的基本模块：**卷积层，池化层，全连接层**。**是其他深度学习模型的基础**

![](https://img-blog.csdnimg.cn/0eb7f8d183ca4ec99778fa83376d8dd5.png)![](https://img-blog.csdnimg.cn/6282368b37c141cbbde3dbb318b91e39.png)  
**5*5 卷积**  
![](https://img-blog.csdnimg.cn/0f4560e659ed45819047ca4a72e66ddd.png)  
使用池化层降低图片对空间信息的敏感度  
![](https://img-blog.csdnimg.cn/3d77245ab7624807bb8a5ed93538ae3a.png)

总结

1.  LeNet-5 是一种用于**手写体**字符识别的非常高效的卷积神经网络。
2.  卷积神经网络能够很好的利用图像的结构信息。
3.  **卷积层的参数较少**，这也是由卷积层的主要特性即**局部连接和共享权重**所决定。

Alexnet
=======

1. 历史
-----

### 1.1 2000 流行的机器学习方法——SVM，核方法

1.  核方法替代了之前的神经网络网络方法，**SVM 对于调参不敏感**，现在也有一些应用
    
2.  **本质上是特征提取**，具体的方法是**选择核函数**来计算，把特征映射到高纬空间，**使得他们线性可分**
    
3.  经过核函数计算之后，原问题可以转化为凸优化问题，这是 2006 年左右的研究热点
    
4.  **核方法有很多漂亮的定理，有很好的数学解释性**
    
5.  **2010 年左右，深度学习才兴起**
    

### 1.2 2000 计算机视觉主要方法——几何学

1.  首先还是对图片进行特征抽取
2.  希望把计算机视觉问题描述成几何问题，建立（非）凸优化模型，可以得到很多漂亮的定理。
3.  可以假设这是一个几何问题，假设这个假设被满足了，可以推出很好的效果

### 1.3 2010 计算机视觉的热点问题——特征工程

1.  特征工程就是怎么抽取一张图片的特征，因为直接输入一张图片效果非常的差
2.  特征描述子：SIFT,SURF  
    ![](https://img-blog.csdnimg.cn/35e7374c4be9482b87e8ced43ba521ea.png)

![](https://img-blog.csdnimg.cn/7637eedf8ecf469ca2b2735b14df09fe.png)  
![](https://img-blog.csdnimg.cn/c67996e3b95e44c09a506c400f388968.png)

### 1.4 硬件的发展奠定了深度学习的兴起

数据的增长，硬件的计算能力奠定了人们对于方法的选择  
![](https://img-blog.csdnimg.cn/06f721b523e544cc8773c3529e5ae178.png)![](https://img-blog.csdnimg.cn/fd598963f74b4155bbd1b727d11e0a1e.png)

### 1.5 ImageNet（2010）

![](https://img-blog.csdnimg.cn/691e74682d7b41d187d84b4d5a4a83a6.png)

1.  AlexNet 赢得了 **2012 年 ImageNet 竞赛冠军**
    
2.  **本质上是一个加强版的 LeNet，更深更大**
    
3.  **AlexNet 主要改进措施：**
    
    1 dropout 和数据增强（正则）  
    2 ReLu（梯度更大）  
    3 MaxPooling（**取最大值，梯度相对增大**）
    
4.  **影响：计算机视觉方法论的改变，从人工提取特征过渡到 CNN 学习特征**
    

![](https://img-blog.csdnimg.cn/36d4d585223a4e65ab725acb826c0187.png)

包含许多特征的深度模型需要大量的有标签数据，才能显著优于基于凸优化的传统方法（如线性方法和核方法）。

1.  relu 替换 sigmoid,relu 的梯度确实是更大，relu 在 0 点处的一阶导数确实是更好一点，他**能够支撑更深的模型**
    
2.  lenet 大家还是认为是一个机器学习的模型，**ALexnet 增大了几十倍**，**量变引起质变，他对整个计算机视觉的改变是观念上的改变**。深度神经网络之前是进行人工特征提取然后用一个标准的机器学习模型比如 SVM，我觉得 SVM 要什么特征比较好，但**深度学习分类器和特征提取器是一起训练的过程**
    

2. ALexnet 架构
-------------

![](https://img-blog.csdnimg.cn/5f349cf64be947259eb8be60d00dc61c.png)![](https://img-blog.csdnimg.cn/f0d22bc3659748b29fe24393f02bb003.png)![](https://img-blog.csdnimg.cn/f29892798b7e4684a75c9101e44d522c.png)  
**网络代码**

```
net = nn.Sequential(
这里，我们使用一个11*11的更大窗口来捕捉对象。
    # 同时，步幅为4，以减少输出的高度和宽度。
    # 另外，输出通道的数目远大于LeNet
    nn.Conv2d(1, 96, kernel_size=11, stride=4, padding=1), nn.ReLU(),
    nn.MaxPool2d(kernel_size=3, stride=2),
    # 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，且增大输出通道数
    nn.Conv2d(96, 256, kernel_size=5, padding=2), nn.ReLU(),
    nn.MaxPool2d(kernel_size=3, stride=2),
    # 使用三个连续的卷积层和较小的卷积窗口。
    # 除了最后的卷积层，输出通道的数量进一步增加。
    # 在前两个卷积层之后，汇聚层不用于减少输入的高度和宽度
    nn.Conv2d(256, 384, kernel_size=3, padding=1), nn.ReLU(),
    nn.Conv2d(384, 384, kernel_size=3, padding=1), nn.ReLU(),
    nn.Conv2d(384, 256, kernel_size=3, padding=1), nn.ReLU(),
    nn.MaxPool2d(kernel_size=3, stride=2),
    nn.Flatten(),
    # 这里，全连接层的输出数量是LeNet中的好几倍。使用dropout层来减轻过拟合
    nn.Linear(6400, 4096), nn.ReLU(),
    nn.Dropout(p=0.5),
    nn.Linear(4096, 4096), nn.ReLU(),
    nn.Dropout(p=0.5),
    # 最后是输出层。由于这里使用Fashion-MNIST，所以用类别数为10，而非论文中的1000
    nn.Linear(4096, 10))

```

**更多细节**

1.  **激活函数从 sigmoid 变成 Relu，减缓梯度消失**
2.  隐藏全连接层后加入了丢弃层（2 个 4096 之后加入了 dropout）
3.  数据增强，将一张图片进行变化，选取多个位置、光照之类的。  
    ![](https://img-blog.csdnimg.cn/39e0a83b5b514cd69fd2663d09f62d76.png)

因为**卷积对位置比较敏感，而且对光照什么的都比较敏感，怎么让你变得不敏感，就是在数据中加入各种变种，训练的时候就模拟这种变化出来，这样神经网络记住数据的能力就变低了**

**复杂度对比**

1.  参数个数增加，每次更新数据增加  
    ![](https://img-blog.csdnimg.cn/e7ae637a3ac440abb1d297e08ed1b0be.png)

3. 总结
-----

1.  AlexNet 是更大更深的 LeNet，**10x 参数个数**，**260x 计算复杂度**
2.  新加入了 dropout，relu，maxpooling，数据增强
3.  标志着新一轮神经网络热潮开始了

使用块的网络 VGG
==========

Alexnet 最大的问题在于长得**不规则**，**结构不甚清晰**，也**不便于调整**。想要把网络做的更深更大需要更好的设计思想和标准框架。

1. VGG 块
--------

**怎么样更好的更深更大？**  
直到现在更深更大的模型也是我们努力的方向，在当时 AlexNet 比 LeNet 更深更大得到了更好的精度，大家也希望把网络做的更深更大。选择之一是使用**更多的全连接层**，**但全连接层的成本很高**；第二个选择是使用更多的卷积层，但缺乏好的指导思想来说明在哪加，加多少。最终 VGG 采取了**将卷积层组合成块，再把卷积块组合到一起的思路**。

**VGG 块可以看作是 AlexNet 思路的拓展**，AlexNet 中将三个相同的卷积层放在一起再加上一个池化层，而 VGG 将其拓展成可以使用任意个 3x3，**不改变输入大小的的卷积层**，**最后加上一个 2x2 的最大池化层**。

**补充：** 为什么使用 2 个 3x3 的卷积核可以代替 5x5 的卷积核？  
5_5 的计算量比较大，在同样计算开销的情况下，我堆叠 3_3 的效果比少量 5*5 的效果好  
![](https://img-blog.csdnimg.cn/e55e4f73ca3141eba01026323fc348ea.png)  
![](https://img-blog.csdnimg.cn/444da107d5a74452aa60f878248f6d8e.png)  
为什么选择 3x3 卷积呢？**在计算量相同的情况下选用更大的卷积核涉及对网络会越**浅，VGG 作者经过实验发现用 3x3 卷积的效果要比 5x5 好，也就是说**神经网络库深且窄的效果会更好**。

2. VGG 架构
---------

多个 VGG 块后接全连接层，**不同次数的重复块得到不同的架构**，如 VGG-16, VGG-19 等，后面的数字取决于网络层数。

可以讲 VGG 看作是**将 AlexNet 中连续卷积的部分**取出加以推广和复制，并删去了 AlexNet 中不那么规整的前几层。  
![](https://img-blog.csdnimg.cn/0816c0cb902b4407bf1c44094db476b6.png)

1.  Alexnet 是一个比较大的 lenet,VGG 是替换成 n 个 VGG 块串联在一起
2.  VGG 较 AlexNet 相比性能有很大的提升，而代价是处理样本速度的降低和内存占用的增加。

![](https://img-blog.csdnimg.cn/b919a2bf6b184526b37c9f4c19d2605d.png)  
![](https://img-blog.csdnimg.cn/f36119d4698c495085b8653c777d8cd9.png)

3. 总结
-----

![](https://img-blog.csdnimg.cn/b6d58b738ab148f387b5d80a40dbd06c.png)  
这些思想影响了后面神经网络的设计，在之后的模型中被广泛使用。

4. 代码
-----

定义 VGG 块

```
# 该函数有三个参数，分别对应于卷积层的数量 num_convs、输入通道的数量 in_channels 和输出通道的数量 out_channels.
import torch
from torch import nn
from d2l import torch as d2l

def vgg_block(num_convs, in_channels, out_channels):
    layers = []
    for _ in range(num_convs):
        layers.append(
            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))
        layers.append(nn.ReLU())
        in_channels = out_channels
    layers.append(nn.MaxPool2d(kernel_size=2, stride=2))
    return nn.Sequential(*layers)


```

实现 VGG 网络结构

```
'''
原始 VGG 网络有 5 个卷积块，其中前两个块各有一个卷积层，后三个块各包含两个卷积层。
第一个模块有 64 个输出通道，每个后续模块将输出通道数量翻倍，直到该数字达到 512。
由于该网络使用 8 个卷积层和 3 个全连接层，因此它通常被称为 VGG-11。'''
conv_arch = ((1, 64), (1, 128), (2, 256), (2, 512), (2, 512))


```

```
# vgg11
# 每个块的高度和块度减半，输出通道数量加倍，最终高度和宽度都是7，通道数为512。最后展平使用全连接层处理
def vgg(conv_arch):
    conv_blks = []
    in_channels = 1
    # 卷积层部分
    for (num_convs, out_channels) in conv_arch:
        conv_blks.append(vgg_block(num_convs, in_channels, out_channels))
        in_channels = out_channels

    return nn.Sequential(*conv_blks, nn.Flatten(),
                         # 全连接层部分
                         nn.Linear(out_channels * 7 * 7, 4096), nn.ReLU(),
                         nn.Dropout(0.5), nn.Linear(4096, 4096), nn.ReLU(),
                         nn.Dropout(0.5), nn.Linear(4096, 10))

net = vgg(conv_arch)


```

5. QA
-----

**Q1: 视觉领域人工特征的研究还有无进展？**

现在在计算机视觉做人工特征是一种 “政治不正确” 的事，可能会因被认为没有 novelty 而发不出 paper 😉

老师认为人工特征提取确实应该被取代掉，随着技术进步可以把这部分工作交给机器，**人去做更高级的事**。

**Q2: 需要学习特征值 / 特征向量 / 奇异值分解的知识吗？**

这门课中不一定会讲，但很多深度学习模型用到矩阵分解的思想，但是用的不多，想学可以学。

网络中的网络（NiN）
===========

![](https://img-blog.csdnimg.cn/907783aff13f46d8815ef9d00309f1f8.png)  
LeNet、AlexNet 和 VGG 都有一个共同的设计模式：通过一系列的**卷积层与池化层**来提**取空间结构特征**；然后通过**全连接层**对**特征的表征进行处理**。AlexNet 和 VGG 对 LeNet 的改进主要在于如何扩大和加深这两个模块。

1. 动机
-----

![](https://img-blog.csdnimg.cn/a9e2de35e4624e41a42fb4337f24d681.png)

1.  全连接层特别占用参数空间，重要的问题是他会带来过拟合
2.  卷积层参数输入通道数_输出通道数_卷积核大小的平方
3.  参数的大头就是**卷积层之后的第一个全连接层**，**很容易过拟合**，**你需要做大量的正则化不要让这一层把你所有的东西都学了**
4.  **NiN 的思想是完全不要全连接层**

2. NiN 块
--------

**核心思想**：一个卷积层后面跟两个 1x1 的卷积层，后两层起到全连接层的作用。  
![](https://img-blog.csdnimg.cn/37bf5b1a94df4b0cbf55a8aaff7079a4.png)

**1*1 的卷积层等价于一个全连接层**（可以**理解成按照输入像素逐一做全连接层**）（每个全连接层都有一个 relu 函数，增加非线性），在这里可以把每个通道数做一下变换

3. NiN 架构
---------

1.  **无全连接层**
2.  交替使用 **NiN 块和步幅为 2 的最大池化层**  
    逐步减小高宽和增大通道数
3.  最后使用**全局平均池化**得到输出  
    其输入通道是类别数

4. NiN Networks
---------------

![](https://img-blog.csdnimg.cn/dae9d250d5f14edaacbe1f7e488b9d04.png)  
NiN 架构如上图右边所示，若干个 NiN 块 (图示中为 4 个块)+ 池化层；**前 3 个块后接最大池化层**，**最后一块连接一个全局平均池化层**。

5. 总结
-----

1.  NiN 块结构：使用卷积层加两个 1x1 卷积层  
    后者**对每个像素**增加了非线性性
2.  NiN 使用全局平均池化层来替代 VGG 和 AlexNet 中的全连接层  
    **不容易过拟合，更少的参数个数**

6. 代码
-----

**NiN 块**

```
import torch
from torch import nn
from d2l import torch as d2l

# 定义NiN块
def nin_block(in_channels, out_channels, kernel_size, strides, padding):
    return nn.Sequential(
        nn.Conv2d(in_channels, out_channels, kernel_size, strides, padding),
        nn.ReLU(), nn.Conv2d(out_channels, out_channels, kernel_size=1),
        nn.ReLU(), nn.Conv2d(out_channels, out_channels, kernel_size=1),
        nn.ReLU())

```

**NiN 模型**

```
net = nn.Sequential(
    nin_block(1, 96, kernel_size=11, strides=4, padding=0),
    nn.MaxPool2d(3, stride=2),
    nin_block(96, 256, kernel_size=5, strides=1, padding=2),
    nn.MaxPool2d(3, stride=2),
    nin_block(256, 384, kernel_size=3, strides=1, padding=1),
    nn.MaxPool2d(3, stride=2), nn.Dropout(0.5),
    # 标签类别数是10
    nin_block(384, 10, kernel_size=3, strides=1, padding=1),
    nn.AdaptiveAvgPool2d((1, 1)),          #全局平均池化，高宽都变成1
    nn.Flatten())             #消掉最后两个维度, 变成(batch_size, 10)

```

全局池化把输入变小了，而且他没有可学习的参数，主要好处是他把模型复杂度降低了，会提升泛化性。坏处就是收敛变慢了

GoogLeNet /inceptionv1
======================

**第一个可以超过 1000 层的卷积神经网络**（**卷积层的个数超过了 1000**）

含并行连结的网络（GoogLeNet）
-------------------

GoogLeNet 吸收了 NiN 中串联网络的思想，并在此基础上做了改进。我们往往不确定到底选取什么样的层效果更好，到底是 3X3 卷积层还是 5X5 的卷积层，诸如此类的问题是 GooLeNet 选择了另一种思路 “小学生才做选择，我全都要”，这也使得 GooLeNet 成为了第一个模型中超过 1000 个层的模型。  
![](https://img-blog.csdnimg.cn/30791924971d4118affce3af7a6b1e26.png)![](https://img-blog.csdnimg.cn/be11e67012c442b9a68dd750c05bf25a.png)

Inception 块
-----------

1.  在 GoogLeNet 中，基本的卷积块被称为 Inception 块（Inception block）  
    ![](https://img-blog.csdnimg.cn/08dcdb61ae724cc29483a7af6f59d95f.png)

**白色的 1*1 卷积可以理解为改变通道数的，蓝色的那个是用来抽取信息的（不抽取空间信息，只抽取通道信息）**  
![](https://img-blog.csdnimg.cn/15a02a27d35242d892313624cbcd2e80.png)  
为什么使用 inception 块？跟 3 × 3 和 5 × 5 的卷积层比起来，inception 块有**更少的参数**个数和**计算复杂度**  
![](https://img-blog.csdnimg.cn/2c06a10d0fd54bf3bc16d2e207a2e359.png)

GoogLeNet 模型
------------

GoogLeNet 一共使用 9 个 Inception 块和全局平均汇聚层的堆叠来生成其估计值。Inception 块之间的最大汇聚层可降低维度。 第一个模块类似于 AlexNet 和 LeNet，Inception 块的组合从 VGG 继承，全局平均汇聚层避免了在最后使用全连接层  
![](https://img-blog.csdnimg.cn/b26a75ec6a904e798532d7a43c8bad62.png)

![](https://img-blog.csdnimg.cn/a93a4538585442efa374d16e56dcca38.png)

1.  第一个模块是 7×7 卷积层。
2.  第二个模块使用两个卷积层：第一个卷积层是 1×1 卷积层；第二个卷积层使用将通道数量增加三倍的 3×3 卷积层。 这对应于 Inception 块中的第二条路径。![](https://img-blog.csdnimg.cn/e318abc197ef4bea8f7c309d2e1aa2e4.png)![](https://img-blog.csdnimg.cn/d97d1dcf1bf048a3a45a13c32017ff10.png)![](https://img-blog.csdnimg.cn/3573126426724df0abe5a00777d66f7e.png)

总结
--

1.  Inception 块相当于一个有 4 条路径的子网络。它通过不同窗口形状的卷积层和最大汇聚层来并行抽取信息，并使用 1×1 卷积层减少每像素级别上的通道维数从而降低模型复杂度。
    
2.  GoogLeNet 将多个设计精细的 Inception 块与其他层（卷积层、全连接层）串联起来。其中 Inception 块的通道数分配之比是在 ImageNet 数据集上通过大量的实验得来的。
    
3.  GoogLeNet 和它的后继者们一度是 ImageNet 上最有效的模型之一：它以较低的计算复杂度提供了类似的测试精度。
    

InceptionV2/V3
--------------

![](https://img-blog.csdnimg.cn/b86894220d244bf7a84cecaa54c72283.png)![](https://img-blog.csdnimg.cn/ca84970122fc4915900274147bc6e4ab.png)

![](https://img-blog.csdnimg.cn/87a3cc7f932943feb026ffcbd56395fa.png)![](https://img-blog.csdnimg.cn/2d4849bbe0024cc18fbb27095e323e49.png)  
![](https://img-blog.csdnimg.cn/d289ba5e3ec34162bc9a9564f21c23cc.png)

![](https://img-blog.csdnimg.cn/de9f0a11029444bb933f2d5b392069e4.png)

Inception v4
------------

Inception v4 和 Inception -ResNet 在同一篇论文《Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning》中介绍

**Inception v4 引入了专用的「缩减块」（reduction block）**，它被用于**改变网格的宽度和高度**。早期的版本并没有明确使用缩减块，但也实现了其功能。  
![](https://img-blog.csdnimg.cn/bc51d794abfa402b97b33fbd2e2dae3e.png)

稠密连接网络（DenseNet）
================

ResNet 中的跨层连接设计引申出了数个后续工作。本节我们介绍其中的一个：稠密连接网络（DenseNet） [1]。 它与 ResNet 的主要区别如图 5.10 所示。  
![](https://img-blog.csdnimg.cn/d33036596f444621aff9cedf1346829a.png)  
_图 5.10 ResNet（左）与 DenseNet（右）在跨层连接上的主要区别：使用相加和使用连结_

图 5.10 中将部分前后相邻的运算抽象为模块 A 和模块 B。**与 ResNet 的主要区别在于，DenseNet 里模块 BB 的输出不是像 ResNet 那样和模块 AA 的输出相加，而是在通道维上连结**。这样模块 A 的输出可以直接传入模块 B 后面的层。在这个设计里，模块 A 直接跟模块 B 后面的所有层连接在了一起。这也是它被称为 “稠密连接” 的原因。

DenseNet 的主要构建模块是**稠密块（dense block）和过渡层（transition layer）**。**前者定义了输入和输出是如何连结的，后者则用来控制通道数，使之不过大。**

5.12.1 稠密块
----------

DenseNet 使用了 ResNet 改良版的 “批量归一化、激活和卷积” 结构，我们首先在 conv_block 函数里实现这个结构。

```
import time
import torch
from torch import nn, optim
import torch.nn.functional as F

import sys
sys.path.append("..") 
import d2lzh_pytorch as d2l
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

def conv_block(in_channels, out_channels):
    blk = nn.Sequential(nn.BatchNorm2d(in_channels), 
                        nn.ReLU(),
                        nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))
    return blk


```

稠密块由多个 conv_block 组成，每块使用相同的输出通道数。**但在前向计算时，我们将每块的输入和输出在通道维上连结。**

```
class DenseBlock(nn.Module):
    def __init__(self, num_convs, in_channels, out_channels):
        super(DenseBlock, self).__init__()
        net = []
        for i in range(num_convs):
            in_c = in_channels + i * out_channels
            net.append(conv_block(in_c, out_channels))
        self.net = nn.ModuleList(net)
        self.out_channels = in_channels + num_convs * out_channels # 计算输出通道数

    def forward(self, X):
        for blk in self.net:
            Y = blk(X)
            X = torch.cat((X, Y), dim=1)  # 在通道维上将输入和输出连结
        return X


```

在下面的例子中，我们定义一个有 2 个输出通道数为 10 的卷积块。使用通道数为 3 的输入时，我们会得到通道数为 3+2×10=233+2×10=23 的输出。卷积块的通道数控制了输出通道数相对于输入通道数的增长，因此也被称为增长率（growth rate）。

```
blk = DenseBlock(2, 3, 10)
X = torch.rand(4, 3, 8, 8)
Y = blk(X)
Y.shape # torch.Size([4, 23, 8, 8])


```

5.12.2 过渡层
----------

由于每个稠密块都会带来通道数的增加，使用过多则会带来过于复杂的模型。过渡层用来控制模型复杂度。它通过 1×1 卷积层来减小通道数，并使用**步幅为 2 的平均池化层减半高和宽**，从而进一步降低模型复杂度。

```
def transition_block(in_channels, out_channels):
    blk = nn.Sequential(
            nn.BatchNorm2d(in_channels), 
            nn.ReLU(),
            nn.Conv2d(in_channels, out_channels, kernel_size=1),
            nn.AvgPool2d(kernel_size=2, stride=2))
    return blk


```

对上一个例子中稠密块的输出使用通道数为 10 的过渡层。此时输出的通道数减为 10，高和宽均减半。

```
blk = transition_block(23, 10)
blk(Y).shape # torch.Size([4, 10, 4, 4])


```

DenseNet 模型
-----------

我们来构造 DenseNet 模型。DenseNet 首先使用同 ResNet 一样的单卷积层和最大池化层。

```
net = nn.Sequential(
        nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),
        nn.BatchNorm2d(64), 
        nn.ReLU(),
        nn.MaxPool2d(kernel_size=3, stride=2, padding=1))


```

类似于 ResNet 接下来使用的 4 个残差块，DenseNet 使用的是 4 个稠密块。同 ResNet 一样，我们可以设置每个稠密块使用多少个卷积层。这里我们设成 4，从而与上一节的 ResNet-18 保持一致。稠密块里的卷积层通道数（即增长率）设为 32，所以每个稠密块将增加 128 个通道。

ResNet 里通过步幅为 2 的残差块在每个模块之间减小高和宽。这里我们则使用过渡层来减半高和宽，并减半通道数。

```
num_channels, growth_rate = 64, 32  # num_channels为当前的通道数
num_convs_in_dense_blocks = [4, 4, 4, 4]

for i, num_convs in enumerate(num_convs_in_dense_blocks):
    DB = DenseBlock(num_convs, num_channels, growth_rate)
    net.add_module("DenseBlosk_%d" % i, DB)
    # 上一个稠密块的输出通道数
    num_channels = DB.out_channels
    # 在稠密块之间加入通道数减半的过渡层
    if i != len(num_convs_in_dense_blocks) - 1:
        net.add_module("transition_block_%d" % i, transition_block(num_channels, num_channels // 2))
        num_channels = num_channels // 2


```

同 ResNet 一样，最后接上全局池化层和全连接层来输出。

```
net.add_module("BN", nn.BatchNorm2d(num_channels))
net.add_module("relu", nn.ReLU())
net.add_module("global_avg_pool", d2l.GlobalAvgPool2d()) # GlobalAvgPool2d的输出: (Batch, num_channels, 1, 1)
net.add_module("fc", nn.Sequential(d2l.FlattenLayer(), nn.Linear(num_channels, 10))) 


```

我们尝试打印每个子模块的输出维度确保网络无误：

```
X = torch.rand((1, 1, 96, 96))
for name, layer in net.named_children():
    X = layer(X)
    print(name, ' output shape:\t', X.shape)


```

输出：

```
0  output shape:     torch.Size([1, 64, 48, 48])
1  output shape:     torch.Size([1, 64, 48, 48])
2  output shape:     torch.Size([1, 64, 48, 48])
3  output shape:     torch.Size([1, 64, 24, 24])
DenseBlosk_0  output shape:     torch.Size([1, 192, 24, 24])
transition_block_0  output shape:     torch.Size([1, 96, 12, 12])
DenseBlosk_1  output shape:     torch.Size([1, 224, 12, 12])
transition_block_1  output shape:     torch.Size([1, 112, 6, 6])
DenseBlosk_2  output shape:     torch.Size([1, 240, 6, 6])
transition_block_2  output shape:     torch.Size([1, 120, 3, 3])
DenseBlosk_3  output shape:     torch.Size([1, 248, 3, 3])
BN  output shape:     torch.Size([1, 248, 3, 3])
relu  output shape:     torch.Size([1, 248, 3, 3])
global_avg_pool  output shape:     torch.Size([1, 248, 1, 1])
fc  output shape:     torch.Size([1, 10])


```

小结
--

1.  在跨层连接上，不同于 ResNet 中将输入与输出相加，DenseNet 在通道维上连结输入与输出。
2.  DenseNet 的主要构建模块是**稠密块和过渡层**。

BN 批量归一化
========

深层神经网络的训练，尤其是使网络在**较短时间内收敛**是十分困难的，**批量归一化 [batch normalization]** 是一种流行且有效的技术，能**加速深层网络的收敛速度**，目前仍被广泛使用。

训练深层网络时的问题
----------

![](https://img-blog.csdnimg.cn/522bb2ef331047c8a56c884c8057467f.png)![](https://img-blog.csdnimg.cn/74eb682d39dc4660a880c0049c4ea0de.png)  
**深度神经网络在训练时会遇到一些问题：**

**收敛速度慢：**

1.  由于训练时**先正向传播后反向传播**，且每层的梯度一般较小，若**网络较深**，则**反向传播**时会出现类似于**梯度消失**的现象，导致**距离数据更近的层梯度较小**，**收敛慢**，而**距离输出更近的层梯度较大**，**收敛快**。然而**底部的层**一般都用于提取**较基础的特征信息**（比如**局部啊边缘啊很简单的纹理信息**），上方的层收敛后，由于底部提取基础特征的层仍在变化，上方的层一直在不停的重新训练，导致整个网络难以收敛，训练较慢。

**内部协变量转移：**

1.  **分布偏移**：偏移在视频课程中并未出现，但在《动手学深度学习》这本书中有提到过，在 4.9. 环境和分布偏移部分。偏移指的是训练数据可能和测试数据的分布不同，比如利用来自真实的猫和狗的照片的训练数据训练模型，然后让模型去预测动画中的猫和狗的图片。  
    这显然会降低正确率也会对模型的进一步优化带来干扰。一般情况下对于分布偏移我们毫无办法，然而，在一些特定场景中，如果假定一些训练数据和测试数据分布的前提条件，就能对分布偏移进行处理，其中之一就是协变量偏移。  
    ![](https://img-blog.csdnimg.cn/5a58f2dc3e5b484cb23ce502429df000.png)

![](https://img-blog.csdnimg.cn/05d22199ae9846639957b084147b9702.png)

2.  **协变量偏移**：协变量偏移假设输入的分布可能随时间变化，但标签函数（条件分布）没有改变。统计学家称这为协变量偏移（covariate shift）并给出了一些解决方案
3.  **内部协变量偏移** (Internal Covariate Shift)：每一层的参数在更新过程中，会改变下一层输入的分布，导致网络参数变幻莫测，难以收敛，神经网络层数越多，表现得越明显。
4.  注意：  
    1：内部协变量偏移这个词与标准的协变量偏移所有区别。  
    2：**能缓解内部协变量偏移仅仅是批量归一化的作者提出的假想，后续论文证实批量归一化实际对内部协变量偏移的缓解帮助不大**  
    3：**批量归一化一般只影响模型的收敛速度，不影响精度**

**过拟合：**

1.  由于网络深度加深，变得更为复杂，使得网络**容易过拟合**。

批量归一化
-----

** 批量归一化 (batch normalization)** 在 [Ioffe & Szegedy, 2015] 中被提出，用于解决上述训练深度网络时的这些问题，然而这只是人们的感性理解，关于批量归一化具体是怎样帮助训练这个问题目前仍待进一步研究。

批量归一化尝试将每个训练中的 mini-batch 小**批量数据**（即会导致参数更新的数据）在每一层的结果进行**归一化，使其更稳定**，归一化指的是对于当前小批量中的所有样本，求出期望和方差，然后将**每个样本减去期望再除以标准差**。

形式化表达
-----

![](https://img-blog.csdnimg.cn/71dd0d8521774426977e75acc2409d94.png)  
**拉伸参数，偏移参数**  
![](https://img-blog.csdnimg.cn/b552ce6341244f958b407cba3b73536a.png)

1.  批量归一化是一个线性变换，可以吧你的均值方差拉到比较好，让你的变化不那么剧烈
2.  **在卷积层中**，我们**将通道视作每个位置的特征**，将每个样本中的每个位置视作一个样本进行计算。每个通道都有着自己的拉伸参数和偏移参数，所有通道加在一起组成了拉伸参数向量和偏移参数向量，若**样本数为 m**，**卷积输出为 p*q**，计算时对 m_p_q 个向量进行批量归一化运算（即视作有 m_p_q 个样本）

**对（B,C,H,W）的输入，其针对哪些维度做归一化处理？** B H W  
![](https://img-blog.csdnimg.cn/aa1bd4233c4e4b15b82e1d17a52f1374.png)![](https://img-blog.csdnimg.cn/ef9660c3395b4ba1a2e8a19e20a53036.png)

![](https://img-blog.csdnimg.cn/30b91a7b8d5e40a98843170cca75a67d.png)  
4. 因为均值和方差是在**每一个随机的小批量**上计算而来，是为噪音，**另外两个参数是可学习的**，**可学习的东西变化不会太剧烈，取决于学习率**。使得 1. 变化不要太剧烈 2. 有一定的**随机性**  
5. 目前工程走在理论的前面，正不正确不知道

![](https://img-blog.csdnimg.cn/e9a1a7ecac214d42bff52098df389e45.png)  
学习率可以调大一点，加速收敛

吴恩达老师深度学习课程中的批量归一化
------------------

吴恩达老师深度学习课程中的批量归一化中的部分内容与本课程有所出入，考虑到批量归一化这部分内容还没有精确的理论解释，目前的认识仅限于直觉，故将两课程中的区别即补充罗列在此作为参考：

1.  关于 dropout：  
    本课中提到**批量归一化有正则化效果，无需再进行 dropout**  
    吴恩达老师课程中提到**批量归一化正则化效果较差，不能作为正则化的手段，必要时需要 dropout**
2.  对于线性层（包括其他带有偏置项的层）后的批量归一化，由于归一化时减去了均值，偏置项被消掉，可以省略归一化层之前的偏置项
3.  标准化的输入能使梯度下降加快，批归一化能使得每层的输入都被归一化，这也是训练更快的原因之一
4.  批量归一化可以使得**不同层之间互相的影响减少**，从而应对数据偏移，增强鲁棒性。

从零实现 BatchNorm
--------------

**定义批量归一化**

```
import torch
from torch import nn
from d2l import torch as d2l

def batch_norm(X, gamma, beta, moving_mean, moving_var, eps, momentum):
    # 通过 `is_grad_enabled` 来判断当前模式是训练模式还是预测模式
    if not torch.is_grad_enabled():
        # 如果是在预测模式下，直接使用传入的移动平均所得的均值和方差
        X_hat = (X - moving_mean) / torch.sqrt(moving_var + eps)
    else:
        assert len(X.shape) in (2, 4)
        if len(X.shape) == 2:
            # 使用全连接层的情况，计算特征维上的均值和方差
            mean = X.mean(dim=0)
            var = ((X - mean)**2).mean(dim=0)
        else:
            # 使用二维卷积层的情况，计算通道维上（axis=1）的均值和方差。
            # 这里我们需要保持X的形状以便后面可以做广播运算
            mean = X.mean(dim=(0, 2, 3), keepdim=True)
            var = ((X - mean)**2).mean(dim=(0, 2, 3), keepdim=True)
        # 训练模式下，用当前的均值和方差做标准化
        X_hat = (X - mean) / torch.sqrt(var + eps)
        # 更新移动平均的均值和方差
        moving_mean = momentum * moving_mean + (1.0 - momentum) * mean
        moving_var = momentum * moving_var + (1.0 - momentum) * var
    Y = gamma * X_hat + beta  # 缩放和移位
    return Y, moving_mean.data, moving_var.data


```

```
class BatchNorm(nn.Module):
    # `num_features`：完全连接层的输出数量或卷积层的输出通道数。
    # `num_dims`：2表示完全连接层，4表示卷积层
    def __init__(self, num_features, num_dims):
        super().__init__()
        if num_dims == 2:
            shape = (1, num_features)
        else:
            shape = (1, num_features, 1, 1)
        # 参与求梯度和迭代的拉伸和偏移参数，分别初始化成1和0
        self.gamma = nn.Parameter(torch.ones(shape))
        self.beta = nn.Parameter(torch.zeros(shape))
        # 非模型参数的变量初始化为0和1
        self.moving_mean = torch.zeros(shape)
        self.moving_var = torch.ones(shape)
    
    def forward(self, X):
        # 如果 `X` 不在内存上，将 `moving_mean` 和 `moving_var`
        # 复制到 `X` 所在显存上
        if self.moving_mean.device != X.device:
            self.moving_mean = self.moving_mean.to(X.device)
            self.moving_var = self.moving_var.to(X.device)
        # 保存更新过的 `moving_mean` 和 `moving_var`
        Y, self.moving_mean, self.moving_var = batch_norm(
            X, self.gamma, self.beta, self.moving_mean, self.moving_var,
            eps=1e-5, momentum=0.9)
        return Y        


```

![](https://img-blog.csdnimg.cn/2ac73c942fb142f0b39c5682788ffa31.png)

CPU 和 GPU
=========

![](https://img-blog.csdnimg.cn/4ab8d7960ae34487a1a9c1fd7450bdf6.png)

CPU
---

![](https://img-blog.csdnimg.cn/438e50adadee47f9a84797c78b32d2a1.png)![](https://img-blog.csdnimg.cn/f5b42966cb564df383e2c862e9f84ffe.png)  
![](https://img-blog.csdnimg.cn/4b408892d5564fe2adfcffb3d4a1220a.png)  
![](https://img-blog.csdnimg.cn/6ebeda25bc814de4a4ca0d38135f2e90.png)

![](https://img-blog.csdnimg.cn/db3eea668c6a4c13bd3a7f5cbed8ff02.png)

GPU
---

![](https://img-blog.csdnimg.cn/f8cd91ff7c754176a5920c6ba66560c5.png)  
![](https://img-blog.csdnimg.cn/09612a04e2c944b384aeba2bd9bf834e.png)![](https://img-blog.csdnimg.cn/7022bad1f6bd457b9e7696a273cfdf36.png)

![](https://img-blog.csdnimg.cn/9e435a0e8ac748fbb89425c14a127084.png)![](https://img-blog.csdnimg.cn/70ff836b37654fda9cacd25bd88f8c26.png)![](https://img-blog.csdnimg.cn/7afa5ffb878248328cf19ccf1ec761da.png)  
![](https://img-blog.csdnimg.cn/dab1f97551ee498d9ed66321582e58b4.png)

Alexnet 比较大主要是因为他的全连接层

![](https://img-blog.csdnimg.cn/ed2a2a15561a4110a245a7d39c4b22a6.png)  
打印 loss 也是传到 cpu，但是非常小

单机多卡并行
------

一台机器可以安装多个 GPU（一般为 1-16 个），在训练和预测时可以将一个小批量计算切分到多个 GPU 上来达到加速目的，常用的切分方案有数据并行，模型并行，通道并行。  
![](https://img-blog.csdnimg.cn/4d338e94897e435c9751c87f6da29177.png)  
**数据并行**

将小批量的数据分为 n 块，**每个 GPU 拿到完整的参数**，对**这一块的数据进行前向传播与反向传播**，**计算梯度**。

数据并行通常性能比模型并行更好，因为对数据进行划分使得各个 GPU 的计算内容更加均匀。  
![](https://img-blog.csdnimg.cn/904e507c7f424769b89b74f40f428ef0.png)

**数据并行的大致流程**  
![](https://img-blog.csdnimg.cn/0f7b741226a8469f8b65c58e6a343e8f.png)  
主要分为五部

1：每个 GPU 读取一个数据块（灰色部分）  
2：每个 GPU **读取当前模型的参数**（橙色部分）  
3：每个 GPU 计算自己拿到数据块的梯度（绿色部分）  
4：**GPU 将计算得到的梯度传给内存（CPU）**（绿色箭头）  
5：**利用梯度对模型参数进行更新**（橙色箭头）  
![](https://img-blog.csdnimg.cn/d70998c923c144769ea9cff901eeb2ae.png)

数据并行并行性较好，主要因为当每个 GPU 拿到的数据量相同时计算量也相似，各个 GPU 的运算时间相近，幸能较好

**模型并行**  
将整个模型分为 n 个部分，每个 GPU 拿到这个部分的参数和负责上一个部分的 GPU 的输出作为输入来进行计算，反向传播同理。

模型并行通常用于模型十分巨大，参数众多，即使在每个 mini-batch 只有一个样本的情况下单个 GPU 的显存仍然不够的情况，但并行性较差，可能有时会有 GPU 处于等待状态。

**通道并行**  
通道并行是数据并行和模型并行同时进行

**总结**

1.  当一个模型能用单卡计算时，通常使用**数据并行**扩展到多卡
2.  **模型并行则用在超大模型上**  
    **Q&A（部分有价值的）**  
    **问 1：若有 4 块 GPU，两块显存大两块显存小怎么办？**  
    答 1： 若 GPU 运算性能相同，则训练取决于小显存的 GPU 的显存大小，更大的显存相当于浪费掉 若 GPU 运算性能不同，一般即为显存大的 GPU 性能更好，可以在分配数据时多分配一点  
    **问 2：数据拆分后，需存储的数据量会变大吗？会降低性能吗？**  
    答 2：每个 GPU 都单独存储了一份模型，这部分的数据量变大了，但如果只考虑运算时的中间变量，则中间变量的大小与数据量呈线性关系，每个 GPU 的数据小了，中间变量也会变小，所有 GPU 的中间变量加起来大小是不变的。 数据拆分后性能会变低，在下节课讲解（数据通讯的开销，每个 GPU 的 batch-size 变小可能无法跑满 GPU，总 batch-size 变大则相同计算量下训练次数变少）

多 GPU 训练实现
----------

![](https://img-blog.csdnimg.cn/80592b6d723843e98dd6e426f427b000.png)  
allreduce: 每个 GPU 的梯度加起来，然后每个 GPU 再拿到自己的梯度  
![](https://img-blog.csdnimg.cn/5c9ccd8b7f544031afbcfd06f8782801.png)

![](https://img-blog.csdnimg.cn/7f45bd229b8c4dc0b6897be01a6d4a69.png)

```
#数据累积和数据复制
def allreduce(data):
    for i in range(1,len(data)):
        data[0][:] += data[i].to(data[0].device)
    for i in range(1,len(data)):
        data[i][:] = data[0].to(data[i].device)

```

![](https://img-blog.csdnimg.cn/d2149fb31e68416497a546d37514ad36.png)![](https://img-blog.csdnimg.cn/d913bd123a8a45ba91d6a9511da4ec4d.png)![](https://img-blog.csdnimg.cn/0bed4d84acf541a380e4b91e60f5ae22.png)

1.  返回的损失 ls 是一个 list，是每一个 GPU 上的损失
2.  然后对每个 GPU 做反向传播，对每个 GPU 上的参数算一下梯度
3.  做 allreduce
4.  每个 GPU 做自己的 sgd

```
#小批量训练
def train_batch(X,y,device_params,devices,lr):
    X_shards,y_shards = split_batch(X,y,devices)
    #在每个GPU上分别计算损失
    ls = [loss(lenet(X_shard,device_W),y_shard).sum() for X_shard,y_shard ,device_W in zip(X_shards,y_shards,device_params)]
    for l in ls:  #反向传播在每个GPU上分别执行
        l.backward()
    #将每个GPU的所有梯度相加，并将其广播到所有GPU
    with torch.no_grad():
        for i in range(len(device_params[0])):
            allreduce([device_params[c][i].grad for c in range(len(devices))])
    #在每个GPU上分别更新模型参数
    for param in device_params:
        d2l.sgd(param,lr,X.shape[0]) # 使用全尺寸的小批量

```

![](https://img-blog.csdnimg.cn/ce434aec0fab47e18878239382a6d8f6.png)![](https://img-blog.csdnimg.cn/6516759c63c14f0b9a2cf7d2db60d425.png)![](https://img-blog.csdnimg.cn/b1e23cc6d3604b179ce2686db56102ef.png)  
**利用 pytorch 框架实现**

```
import torch
from torch import nn
from d2l import torch as d2l

```

```
#搭建ResNet18模型
def resnet18(num_classes,in_channels=1):
    """经过修改的ResNet18模型"""
    def resnet_block(in_channels,out_channels,num_residuals,first_block=False):
        blk = []
        for i in range(num_residuals):
            if i == 0 and not first_block:
                blk.append(d2l.Residual(in_channels,out_channels,use_1x1conv=True,strides=2))
            else:
                blk.append(d2l.Residual(out_channels,out_channels))
        return nn.Sequential(*blk)

    #该模型使用了更小的卷积核、步长和填充，而且删除了最大汇聚层
    net = nn.Sequential(
        nn.Conv2d(in_channels,64,kernel_size=3,stride=1,padding=1),
        nn.BatchNorm2d(64),
        nn.ReLU())
    net.add_module("resnet_block1",resnet_block(64,64,2,first_block=True))
    net.add_module("resnet_block2",resnet_block(64,128,2))
    net.add_module("resnet_block3",resnet_block(128,256,2))
    net.add_module("resnet_block4",resnet_block(256,512,2))
    net.add_module("global_avg_pool",nn.AdaptiveAvgPool2d((1,1)))
    net.add_module("fc",nn.Sequential(nn.Flatten(),nn.Linear(512,num_classes)))
    return net

```

```
net = resnet18(10)
#获得GPU列表
devices = d2l.try_all_gpus()

```

```
def train(net,num_gpus,batch_size,lr):
    train_iter,test_iter = d2l.load_data_fashion_mnist(batch_size)
    devices = [d2l.try_gpu(i) for i in range(num_gpus)]
    #初始化网络
    def init_weights(m):
        if type(m) in [nn.Linear,nn.Conv2d]:
            nn.init.normal_(m.weight,std=0.01)
    net.apply(init_weights)
    #在多个GPU上设置模型
    net = nn.DataParallel(net,device_ids=devices)
    trainer = torch.optim.SGD(net.parameters(),lr)
    loss = nn.CrossEntropyLoss()
    timer,num_epochs = d2l.Timer(),10
    animator = d2l.Animator('epoch','test acc',xlim=[1,num_epochs])
    for epoch in range(num_epochs):
        net.train()
        timer.start()
        for X,y in train_iter:
            trainer.zero_grad()
            X,y = X.to(devices[0]),y.to(devices[0])
            l = loss(net(X),y)
            l.backward()
            trainer.step()
        timer.stop()
        animator.add(epoch+1,(d2l.evaluate_accuracy_gpu(net,test_iter),))
    print(f'test acc:{animator.Y[0][-1]:.2f},{timer.avg():.1f}s/round,'
          f'at{str(devices)}')

```

**Q2: 是否可以通过把 resnet 中的卷积层全替换成 mlp 来实现一个很深的网络？**

可以，有这样做的 paper，但是通过一维卷积（等价于全连接层）做的，如果直接换成全连接层很可能会过拟合。  
//**1*1 卷积层等价于全连接层的特殊版本**

**Q3: 为什么 batch norm 是一种正则但只加快训练不提升精度？**

老师也不太清楚并认为这是很好的问题，可以去查阅论文。

**Q4: all_reduce, all_gather 主要起什么作用？实际使用时发现 pytorch 的类似分布式 op 不能传导梯度，会破坏计算图不能自动求导，如何解决？**

all_reduce 是把 n 个东西加在一起再把所有东西复制回去，all_gather 则只是把来自不同地方东西合并但不相加。使用分布式的东西会破坏自动求导，跨 GPU 的自动求导并不好做，老师不确定 pytorch 能不能做到这一功能，如果不能就只能手写。

**Q5: 两个 GPU 训练时最后的梯度是把两个 GPU 上的梯度相加吗？**

是的。mini-batch 的梯度就是每个样本的梯度求和，多 GPU 时同理，每个 GPU 向将自己算的那部分样本梯度求和，最后再将两个 GPU 的计算得的梯度求和。

**Q6: 为什么参数大的模型不一定慢？flop 数多的模型性能更好是什么原理？**

**性能取决于每算一个乘法需要访问多少个 bit**，计算量与内存访问的比值越高越好。通常 CPU/GPU 不会被卡在频率上而是访问数据 / 内存上，所以参数量小，算力高的模型性能较好（如卷积，矩阵乘法）。

**Q7: 为什么分布到多 GPU 上测试精度会比单 GPU 抖动大？**

抖动是因为学习率变大了，** 使用 GPU 数对测试精度没有影响，只会影响性能。** 但为了得到更好的速度需要把 batchsize 调大，使得收敛情况发生变化，把学习率上调就使得精度更抖。

**Q8: batchsize 太大会导致 loss nan 吗？**

不会，batchsize 中的 loss 是求均值的，**理论上 batchsize 更大数值稳定性会更好**，出现数值不稳定问题可能是学习率没有调好。

Q9: GPU 显存如何优化？

显存手动优化很难，靠的是框架，pytorch 的优化做的还不错。除非特别懂框架相关技术不然建议把 batchsize 调小或是把模型做简单一点。

Q11: parameter server 可以和 pytorch 结合吗，具体如何实现？

pytorch 没有实现 parameter server，但 mxnet 和 tensorflow 有。但是有第三方实现如 byteps 支持 pytorch。

Q12: 用了 nn.DataParallel()，是不是数据集也被自动分配到了多个 GPU 上？

是的。在算 net.forward() 的时候会分开。

Q13: 验证集准确率震荡大那个参数影响最大？

学习率。

Q14: 为了让网络前几层能够训练能否采用不同 stage 采用不同学习率的方法？

可以，主要的问题是麻烦，不好确定各部分学习率相差多少。

Q15: 在用 torch 的数据并行中将 inputs 和 labels 放到 GPU0 是否会导致性能问题，因为这些数据最终回被挪一次到其他 GPU 上。

数据相比梯度来说很少，不会对性能有太大影响。但这个操作看上去的确很多余，老师认为不需要做，但不这样做会报错。

Q16: 为什么 batchsize 较小精度会不怎么变化？

学习率太大了，batchsize 小学习率就不能太大。

Q17: 使用两块不同型号 GPU 影响深度学习性能吗？

需要算好两块 GPU 的性能差。如一块 GPU 的性能是另一块的 2 倍，那么在分配任务时也应该分得 2 倍的任务量。保证各 GPU 在同样时间内算完同一部分。

分布式训练
-----

### 分布式计算

本质上来说和之前讲的单机多卡并行没有区别。二者之间的区别是分布式计算是通过网络把数据从一台机器搬到另一台机器  
![](https://img-blog.csdnimg.cn/8f2b908c5a984160b14b8e522cc1a34b.png)

### GPU 机器架构

总的来说，gpu 到 gpu 的通讯是很快的，gpu 到 cpu 慢一点。机器到机器更慢。因而总体性能的关键就是尽量在本地做通讯而少在机器之间做通讯  
![](https://img-blog.csdnimg.cn/64c63924ed514fbeaa11aac6601f3b97.png)  
**2.1 样例：计算一个小批量**

1.  **每个 worker 从参数服务器那里获取模型参数**：首先把样本复制到**机器的内存**，然后把样本分到**每个 gpu** 上
2.  **复制参数到每个 gpu 上：同样，先把每一次的参数放到内存里，然后再复制到每个 gpu 上**
3.  **每个 gpu 计算梯度**
4.  再**主内存**上把所有 gpu 上的梯度加起来
5.  **梯度从主内存传回服务器**
6.  **每个服务器对梯度求和，并更新参数**

![](https://img-blog.csdnimg.cn/16a69ac22bde42c28d377a7db69376a1.png)  
![](https://img-blog.csdnimg.cn/812f6c6cab8f45fba63bf5c4eeee1b7c.png)

**2.2 总结**  
由于 gpu 到 gpu 和 gpu 到内存的通讯速度还不错，因此我们尽量再本地做聚合（如梯度相加），并减少再网络上的多次通讯

### 关于性能

**3.1 对于同步 SGD：**

1.  这里每个 worker 都是同步计算一个批量，称为**同步 SGD**
2.  假设有 n 个 gpu，每个 gpu 每次处理 b 个样本，那么同步 SGD 等价于再单 gpu 运行批量大小为 nb 的 SGD
3.  再理想情况下，n 个 gpu 可以得到相对单 gpu 的 n 倍加速  
    **3.2 性能：**  
    ![](https://img-blog.csdnimg.cn/a62571e2a6f84c21899f2e97d57e1154.png)

**3…3 性能的权衡**  
![](https://img-blog.csdnimg.cn/b63414b8e10d45a0b4bd5bbb77327fbc.png)![](https://img-blog.csdnimg.cn/c0a106ed109f4be58c7c573611b025eb.png)  
inception 比 3_3 或者 5_5 的卷积要小，适合做并行  
**总结**

1.  分布式同步数据并行是多 gpu 数据并行在多机器上的拓展
2.  网络通讯通常是瓶颈
3.  需要注意使用特别大的批量大小时的收敛效率
4.  更复杂的分布式有异步、模型并行（这里没有介绍）

数据增广
====

![](https://img-blog.csdnimg.cn/ad93f594d9ae44308e65260f694256f6.png)  
![](https://img-blog.csdnimg.cn/fe75759ed1294505955889b4af95cb2b.png)  
可以理解为一个正则项，作用在训练的时候。  
![](https://img-blog.csdnimg.cn/0e07c8f896464c26a36dc196b54dfada.png)  
![](https://img-blog.csdnimg.cn/c79fe4b9ce504c26b1693190c4d8a304.png)  
![](https://img-blog.csdnimg.cn/40f795dc4c7c41d6b886aaa686365d05.png)  
可以理解为增广没有改变均值但是改变了方差使得方差更大了

微调
==

![](https://img-blog.csdnimg.cn/a8e416f55d6442ba95724654b248f4fb.png)![](https://img-blog.csdnimg.cn/0786a9a0efd04b7e8087e60dd4087367.png)![](https://img-blog.csdnimg.cn/685eb503b8b042d1830c21724f2a1765.png)![](https://img-blog.csdnimg.cn/0868ec52c4dc4aa3ba9c5f12d4676525.png)![](https://img-blog.csdnimg.cn/48f5822b235e473a845c84ca9b009bfc.png)  
**固定底层参数，你的模型复杂度变低了，模型变小了，所以可以认为是一个更强的正则化的效果 。在数据很小的情况下，全部训练参数很容易过拟合**

![](https://img-blog.csdnimg.cn/17e4e480ab0a49829d549e161413a06b.png)  
![](https://img-blog.csdnimg.cn/9a465e6a03ea424b8a8020136ceb57eb.png)  
数据不平衡主要是对上层影响比较大  
![](https://img-blog.csdnimg.cn/93174c05f4674de1bb3186d00aa97f24.png)  
微调对学习率不敏感，固定的就好

样式迁移
====

[参考](https://blog.csdn.net/jerry_liufeng/article/details/120879826)  
![](https://img-blog.csdnimg.cn/4bcdbffb2e1746f0b4f43d5c7f264af5.png)  
带来滤镜的灵活性  
![](https://img-blog.csdnimg.cn/4f598ad442b54699ab8eab259c02591b.png)

序列模型
====

序列数据及其统计工具
----------

![](https://img-blog.csdnimg.cn/508918b5774443629afe9d17364e1312.png)![](https://img-blog.csdnimg.cn/5e700130dadb4064a5bd0aefbcf97fa1.png)  
总结：

1.  时序模型中，当前数据与之前的观察数据是相关的
2.  自回归模型使用自身过去数据来预测未来
3.  **马尔科夫模型假设当前数据只根最近少数数据相关**
4.  **潜变量模型使用潜变量来概括历史信息**

**序列模型的统计工具**  
![](https://img-blog.csdnimg.cn/a3f96a8c1f964e17b5466fd56e88386b.png)![](https://img-blog.csdnimg.cn/84c37bce55ee40b6926dd3f3a4672292.png)

对 x1-x_t-1 的数据进行建模，f() 可以认为是一个机器学习模型  
和之前不一样，之前是给定图片去预测他的标号，标号和图片不是一个东西，现在我的**标号和数据样本其实是一个东西**，所以叫做**自回归模型**（假设是回归的话）

![](https://img-blog.csdnimg.cn/de4266989be44820aa1b11cdd661a171.png)

马尔科夫假设
------

![](https://img-blog.csdnimg.cn/e4671a963ebb4fa88a484239f909ff2c.png)

潜变量模型
-----

1.  可以认为 ht 是一个向量，甚至是一个数都行
2.  相当于我现在可以建两个模型了，一个是根据前面的 h 和前面的 t 算现在的 h, 另一个利用现在的 H 和之前的 x 算现在的 x  
    ![](https://img-blog.csdnimg.cn/c2faef31fdde4443885e5be81e64d6fa.png)  
    ![](https://img-blog.csdnimg.cn/bba3df88532c4201940de247aa0c0cda.png)  
    RNN 是属于一个潜变量模型。

RNN 使用了**隐藏层来记录过去发生的所有事件的信息**，从而引入时序的特性，并且避免常规序列模型**每次都要重新计算前面所有已发生的事件而带来的巨大计算量**。

马尔科夫假设 MLP 模型训练
---------------

**数据生成：**  
![](https://img-blog.csdnimg.cn/8242b957207e4a01ab95e7b855e3d980.png)  
**马尔科夫假设：**  
![](https://img-blog.csdnimg.cn/960211ef79514573a26e043aec4302ab.png)  
![](https://img-blog.csdnimg.cn/7eddb949d1a74291a80e9f3488182865.png)  
![](https://img-blog.csdnimg.cn/42a655cdefcc4f8b8da9983b00057aad.png)  
让我们看看这在实践中意味着什么。首先是检查模型对发生在下一个时间步的事情的预测能力有多好，也就是 **单步预测**（one-step-ahead prediction）。  
![](https://img-blog.csdnimg.cn/c491945a37a442cc89fcff8b1041808a.png)  
在几个预测步骤之后，预测结果很快就会衰减到一个常数。为什么这个算法效果这么差呢？最终事实是由于**错误的累积**。  
![](https://img-blog.csdnimg.cn/0a65fad83d3447d18e991d9319aa8f30.png)

QA
--

![](https://img-blog.csdnimg.cn/0d23ff590f294c5eb46f267d44c0c19b.png)  
两者不同，但是潜变量是可以用隐马尔科夫假设的（RNN 就用了），潜变量是说我建模的时候是怎么建模，隐马尔可夫是说是和之前的多少数据相关

RNN 循环神经网络
==========

![](https://img-blog.csdnimg.cn/4cc1a5f856a541148edf03927610fbca.png)

**怎么吧潜变量自回归模型转化成 RNN？**

**ot 是用 ht 预测的输出，ht 不能用 xt（当前）而是用的 h_t-1, 计算损失的时候是 ot 和 xt 之间的关系计算损失**  
xt 是用来更新  
![](https://img-blog.csdnimg.cn/a969816d0adc4c239bc6d909bcb6560f.png)  
最简单的 RNN 是通过 W_hh 存储时序信息的

流程如下，首先有一个输入序列，对于时刻 t，我们用 t-1 时刻的输入 xt-1 和潜变量 ht-1 来计算新的潜变量 ht。同时，对于 t 时刻的输出 ot，则直接使用 ht 来计算得到。注意，计算第一个潜变量只需要输入即可（因为前面并不存在以往的潜变量）。  
![](https://img-blog.csdnimg.cn/a6ea98d51b7e4bbcb359eeefee8ed20c.png)  
值得注意的是，**RNN 本质也是一种 MLP**，尤其是**将 ht-1 这一项去掉时就完全退化成了 MLP**。RNN 的核心其实也就是 ht-1 这一项，它使得模型可以和前面的信息联系起来，**将时序信息储存起来**，**可以把 RNN 理解为是包含时序信息的 MLP。**

梯度裁剪
----

在 T 个时间步中进行反向传播，会由于产生 **O(T) 长度**的梯度乘法链，导致导数数值不稳定，这里使用一个限制θ，通常为 5 到 10，来**控制梯度乘法链的长度**。使用如下的公式  
![](https://img-blog.csdnimg.cn/53b1b5b2595948a9b178198e002cd27a.png)  
就算就一个单隐藏层，但是我会做 T= 35 步迭代，所以有点像一个长度为 35 层的 MLP，至少是 35 层因为每步不止一个矩阵乘法，会发生梯度爆炸。  
![](https://img-blog.csdnimg.cn/131b4e1f65fd47b29de9fdb2586601ed.png)![](https://img-blog.csdnimg.cn/0ed2e96ec13f449e870ded3fb1ed3b4f.png)

等价于吧所有层的梯度拼在一起，再对他求 L2 norm  
![](https://img-blog.csdnimg.cn/9759818446bd4842b6fbd7c309246814.png)![](https://img-blog.csdnimg.cn/0db242215d574ada9572d87a795792f0.png)  
梯度爆炸解决策

大于某一个 threshold, 方向保持，步长按 threshold。

![](https://img-blog.csdnimg.cn/15d540e76c3d4864bf40caa62d29fdf5.png)  
**梯度弥散**

**后面层梯度能得到有效更新，数值计算的原因，到前面层梯度已经很小了，参数不能得到很好更新，这就是梯度弥散**，梯度弥散在下一节 LSTM 中介绍。

更多的 RNNs
--------

![](https://img-blog.csdnimg.cn/e7a6acd1d5f649aca14143053349845e.png)![](https://img-blog.csdnimg.cn/1fb40c896bcf4bfca877ee897780284f.png)

门控循环单元 GRU
==========

1. 动机：如何关注一个序列
--------------

1.  做 RNN 的时候处理不了太长的序列，这是因为你**把序列学习全部放在一个隐藏状态里面**，所有东西都放进去，当**时间很长的时候隐藏状态可能就累计了太多东西**了，**对于刚开始的学习以及不太容易抽取出来了**。
    
2.  **并不是所有的观察值都同等重要，比如电影的帧与帧其实都差不多，就是场景切换的时候可能会很重要。但是 RNN 没有这种机制**
    

![](https://img-blog.csdnimg.cn/fa1be613744e4cfb9950f47f3e4ad4c5.png)  
想只记住相关的观察需要：  
3. 能关注的机制（**更新门**）：顾名思义，是否需要**根据我的输入，更新隐藏状态**  
4. 能遗忘的机制（**重置门**）：**更新候选项时，是否要考虑前一隐藏状态**。

**GRU 网络对 LSTM 网络的改进有两个方面：**

1、将**遗忘门和输入门**合并为一个门：**更新门**，此外另一门叫做重置门。

2、**不引入额外的内部状态 c**，直接在**当前状态 ht 和历史状态 ht-1 之间引入线性依赖关系**。

2. 门的概念
-------

下图描述了门控循环单元中的重置门和更新门的输入，输入是由当前时间步的输入和前一时间步的隐藏状态给出。两个门的输出是由使用 **sigmoid 激活函数**的两个全连接层给出。

![](https://img-blog.csdnimg.cn/c61898ef425244aa9d6aa44325d92723.png)

1.  更新门 Zt，重置门 Rt 的公式大体相同，唯一不同的是学习到的参数。
    
2.  需要注意的是，计算门的方式和原来 RNN 的实现中计算新的隐状态相似，只是激活函数改成了 sigmoid。
    
3.  门本来是电路中的一个概念，**0,1 代表不同的电平**，**可以用于控制电路的通断**。此处 sigmoid 将门的数值归一化到 0 到 1 之间，是一种 "软更新" 方式。而从后面的公式上可以看出，本讲课程采用的是低电平有效（越靠近 0，门的作用越明显）的方式控制。
    

3. 候选隐状态
--------

![](https://img-blog.csdnimg.cn/b0886bb4cf324065963f9e3b6047771f.png)![](https://img-blog.csdnimg.cn/95108a220f26486699f597c60dd949a8.png)

![](https://img-blog.csdnimg.cn/c7b6916e3f19453e8ca4de88fd62ed8a.png)  
**为什么叫候选隐状态？**

**在 RNN 中，这个所谓的候选隐状态就是当前步的隐状态**（Rt 无限接近 1 时）。**但是由于引入了更新门，我们需要考虑是直接沿用上一步的隐藏状态，还是像 RNN 一样使用当前步计算的隐状态**。所以这个结合了当前输入计算的隐状态，**不能立马变成当前的 Ht**，而是**需要用更新门和前一隐状态做一个加权**，所以它是一个候选项。

4. 真正的隐状态
---------

![](https://img-blog.csdnimg.cn/cecea54d6439475c9ca74f6d40265dce.png)  
~H_t 会看 Ht-1 和 Xt，Z 尽量不看 Xt

用更新门对**候选隐状态**和**前一隐状态**做加权，得到**当前步隐状态**的值。

如果 zt 无限接近于 0，更新起作用，候选隐状态 “转正”，变为当前隐状态。

如果 zt 无限接近于 1，更新不起作用，当前隐状态还是沿用前一隐状态。

5. 总结
-----

![](https://img-blog.csdnimg.cn/fcb4e89709b740da9bf357ff8b0b1b9f.png)  
上图四行公式概括了 GRU 模型。在 RNN 的基础上，最重要的是引入了**更新门和重置门**，来**决定前一隐状态对当前隐状态的影响**。以最开始的猫鼠序列的例子来说，如果我的模型一直看到猫，模型可以学习到隐状态不怎么去更新，于是隐状态一直保留了猫的信息，而看到老鼠，隐状态才进行更新。  
![](https://img-blog.csdnimg.cn/c6b871990f844a45912c8bb00c21f40e.png)

1.  这些设计可以帮助我们处理循环神经网络中的**梯度消失问题**，并**更好地捕获时间步距离很长的序列的依赖关系。**
2.  例如，如果整个子序列的所有时间步的更新门都接近于 1，则无论序列的长度如何，在序列起始时间步的旧隐藏状态都将很容易保留并传递到序列结束。

**一个与 RNN 的联动在于：**  
如果更新门完全发挥作用（无限接近于 0），重置门不起作用（无限接近于 1），此时 GRU 模型退化为 RNN 模型。

6. QA
-----

**问题：GRU 为什么需要两个门？**

1.  重置门和更新门各司其职。**重置门单方面控制自某个节点开始**，**之前的记忆（隐状态）不在乎了，直接清空影响**，同时也需要更新门帮助它实现记忆的更新。**更新门更多是用于处理梯度消失问题，可以选择一定程度地保留记忆，防止梯度消失。**
    
2.  **重置门影响的是当前步新的候选隐状态的计算**，**更新门影响的是当前步隐状态的更新程度**。
    

长短期记忆网络（LSTM）
=============

**什么是长短期记忆？**

在**循环神经网络**中，记忆能力分为**短期记忆、长期记忆和长短期记忆**。

1、**短期记忆**

短期记忆指简单循环神经网络中的**隐状态 h**。因为隐状态 h 存储了历史信息，但是隐状态**每个时刻**都会被重写，因此可以看做是一种短期记忆（short-term memory）。

2、**长期记忆**

长期记忆指神经网络学习到的**网络参数**。因为网络参数一般是在**所有 “前向” 和“后向”计算都完成后，才进行更新**，隐含了从所有训练数据中学习到的经验，并且**更新周期要远远慢于短期记忆**，所以看做是长期记忆（long-term memory）。

3、长短期记忆

在 LSTM 网络中，由于遗忘门的存在，如果选择遗忘大部分历史信息，则**内部状态 c** 保存的信息偏于短期，而如果选择只遗忘少部分历史信息，那么内部状态偏于保存更久远的信息，所以内部状态 c 中保存信息的历史周期要长于短期记忆 h，又短于长期记忆（网络参数），因此称为长短期记忆（long short-term memory）。

1. 长短期记忆网络：
-----------

![](https://img-blog.csdnimg.cn/1090189092d44d84bbb05fb897f38f53.png)  
可以说，长短期记忆网络的设计灵感来自于计算机的逻辑门。 长短期记忆网络引入了记忆元（memory cell），或简称为单元（cell）。 有些文献认为记忆元是隐状态的一种特殊类型， 它们与隐状态具有相同的形状，其设计目的是用于记录附加的信息。 为了控制记忆元，我们需要许多门。 其中一个门用来从单元中输出条目，我们将其称为输出门（output gate）。 另外一个门用来决定何时将数据读入单元，我们将其称为输入门（input gate）。 我们还需要一种机制来重置单元的内容，由遗忘门（forget gate）来管理， 这种设计的动机与门控循环单元相同， 能够通过专用机制决定什么时候记忆或忽略隐状态中的输入。 让我们看看这在实践中是如何运作的。

### 1.1 门

![](https://img-blog.csdnimg.cn/f63fde4dd63f433e8eb8ee2e5bad59bb.png)  
这三个门的算式和普通 RNN 计算 Ht 算式相同。

### 1.2 候选记忆单元

Ct_hat 跟之前 RNN 的更新计算是一样的  
![](https://img-blog.csdnimg.cn/35e4e887695049bfbd5a53652622184b.png)  
**相当于在 ht-1 到 ht 的预测中又加了一层隐藏单元**  
![](https://img-blog.csdnimg.cn/c95626c6c96548e697d980dc109b073a.png)

### 1.3 记忆单元

![](https://img-blog.csdnimg.cn/5bcf44cf60524a3d983fc1edf1242ad1.png)  
如果遗忘门始终为 (1) 且输入门始终为(0)， 则过去的记忆元 将随时间被保存并传递到当前时间步。 引入这种设计是为了**缓解梯度消失问题**， 并**更好地捕获序列中的长距离依赖关系**。  
![](https://img-blog.csdnimg.cn/3dceee0cbacd4c149bd85b47d53b68ff.png)![](https://img-blog.csdnimg.cn/e7814991973e45d1b5379bfd771368ac.png)

**LSTM 的关键就是记忆单元**，水平线在图上方贯穿运行。

**记忆单元类似于传送带。直接在整个链上运行**，只有一些**少量的线性交互**。**信息在上面流传保持不变会很容易。**  
![](https://img-blog.csdnimg.cn/3b1dd39f13074ff998196a00d09811a3.png)  
H 是一个 [-1,1] 之间的数字，C 可以用来存储信息，他可以做到比较大，是没有数值限制的

### 1.4 隐状态

记忆单元经过计算达到 [-2,+2], 所以我还想隐状态在[-1,1] 之间的话需要再做一次 tanh  
![](https://img-blog.csdnimg.cn/0838feea69574e4bbd7decba5b21f7a6.png)  
**最后**，我们需要**定义如何计算隐状态**， 这就是**输出门发挥作用的地方**。 在长短期记忆网络中，它仅仅是记忆元的的门控版本。 这就确保了 Ht 的值始终在区间 ((-1, 1)) 内.

**只要输出门接近 1，我们就能够有效地将所有记忆信息传递给预测部分， 而对于输出门接近 (0)，我们只保留记忆元内的所有信息，而不需要更新隐状态。**  
![](https://img-blog.csdnimg.cn/4c50c8a86e804bd9a987e28bceb136ac.png)

深度循环神经网络
========

![](https://img-blog.csdnimg.cn/d4d6665058c742739cae41098d0e22ba.png)![](https://img-blog.csdnimg.cn/6af2e41fb3ec42e9ada6a8ed914f5335.png)![](https://img-blog.csdnimg.cn/0b37044f74f84d49949838a0d181e8e5.png)

双向循环神经网络
--------

![](https://img-blog.csdnimg.cn/d6bbece3de6b4e918ac5fdd702ea5fa8.png)

1.  第一个隐藏层正常输，第二个隐藏层吧输入反一下，再把输出反一下，然后输出去和前一个的输出一一对应的做 concat
2.  正向和反向的 weight 是 concate 在一起的，不是相加或者其他操作

双向循环神经网络的错误应用
-------------

1.  比如说我给你两个东西去推理下一个，但是训练的时候不行，因为我看不到未来的东西
2.  双向 LSTM 特别不适合做推理，几乎不能用在预测下一个词上面，主要的应用是对一个句子（序列）做特征提取  
    ![](https://img-blog.csdnimg.cn/c8d4147dc10e474d8e1a753723154cd0.png)![](https://img-blog.csdnimg.cn/5c5f0128c8b141ae81cbd10334c04fbe.png)

编码器解码器结构
========

![](https://img-blog.csdnimg.cn/9515809ca7cd4a94bb26bb4bbc5d911c.png)![](https://img-blog.csdnimg.cn/489f553de8a940a883bc5b7673c3961f.png)  
![](https://img-blog.csdnimg.cn/bac15337706649a38f68116f4dc11e1d.png)

Seq2Seq
=======

1.  编码器吧最后一个隐藏状态传给解码器，这个隐藏状态包括这个句子的信息
2.  双向可以做 encoder 不能做 decoder
3.  decoder 吧上一个时间步的输出当做输入，同时隐藏状态也过来  
    ![](https://img-blog.csdnimg.cn/c01a2de8885e4de6a88c75b7d85d81c7.png)![](https://img-blog.csdnimg.cn/e2199f9fef7b40ae9ae709a5b0e3ffcd.png)
4.  训练的时候是用真正的 target 输入，就算上一时刻输出错了也没关系
5.  推理和训练不一样  
    ![](https://img-blog.csdnimg.cn/547caf5978214b61aba4e7a5a971f7dc.png)  
    ![](https://img-blog.csdnimg.cn/e9d6b6f3cb1043ce8ebe3f17b4f39c31.png)![](https://img-blog.csdnimg.cn/40d087b4e7814db3ae1058f07cffdbd9.png)

注意力机制
=====

![](https://img-blog.csdnimg.cn/9e6ef98c69484273a9c7c20de70ffae5.png)

1.  最大池化就是把最大的抽出来，我也不知道要干嘛，反正就把最大的东西抽出来；卷积的话就是一个核，就把所有的东西都弄出来，一般是比较容易抽取的特征被抽取出来，比如大量的像素和饱和的颜色
2.  **随意线索就是你想要干嘛**，**key 和 value 就是环境那些不随意线索**，比如报纸咖啡杯等等都是一些环境中的东西，**他的本身叫做 key, 他会对应一个 value**，key 和 value 可以是一样可以是不一样，**咖啡杯那个东西就是 key，就是他的属性**,**value 就是他对我有什么用**
3.  注意力机制也可以叫做 quary pooling，他会根据你的 quary 去做一些有偏向性的选择一些键值对，quary 相当于有自己的想法我要干嘛，区别于之前层在于**显式的加入了 quary 这个东西**——**根据我的查询去寻找我感兴趣的东西**

![](https://img-blog.csdnimg.cn/f219184514464577bb657e2d138de71a.png)  
![](https://img-blog.csdnimg.cn/b77102c43c8a4fa5ba81aa3e31ac3c4d.png)![](https://img-blog.csdnimg.cn/1254351800e54f43ae52c7d4e696b725.png)  
![](https://img-blog.csdnimg.cn/5eca5fc312d44e138109f5ad0aad4041.png)  
![](https://img-blog.csdnimg.cn/3acd52afcac2495cab33d7079e1d6348.png)  
之前的那些东西都是用不随意线索，**不能是你告诉我你想要什么东西**，只能说给我一个数据我自己去看

注意力分数
=====

![](https://img-blog.csdnimg.cn/bea838e355ba4e0e9fce246e8a20da1b.png)![](https://img-blog.csdnimg.cn/4a3b726bd1ef4c46bc8713e7c1150fe7.png)

![](https://img-blog.csdnimg.cn/9579bd1d14c9419aa4c3ebccb323f57e.png)

掩蔽 softmax 操作
-------------

正如上面提到的，softmax 操作用于输出一个概率分布作为注意力权重。 在某些情况下，并非所有的值都应该被纳入到注意力汇聚中。 例如，为了在 9.5 节中高效处理小批量数据集， 某些文本序列被填充了没有意义的特殊词元。 为了仅将有意义的词元作为值来获取注意力汇聚， 我们可以指定一个有效序列长度（即词元的个数）， 以便在计算 softmax 时过滤掉超出指定范围的位置。 通过这种方式，我们可以在下面的 masked_softmax 函数中 实现这样的掩蔽 softmax 操作（masked softmax operation）， 其中任何超出有效长度的位置都被掩蔽并置为 0。

```
import math
import torch
from torch import nn
from d2l import torch as d2l


```

```
# 掩码Softmax操作
def masked_softmax(X, valid_lens):
    """通过在最后一个轴上遮盖元素来执行 softmax 操作"""
    # `X`: 3D tensor, `valid_lens`: 1D or 2D tensor
    if valid_lens is None:
        return nn.functional.softmax(X, dim=-1)散
    else:
        shape = X.shape
        if valid_lens.dim() == 1:
            valid_lens = torch.repeat_interleave(valid_lens, shape[1])
        else:
            valid_lens = valid_lens.reshape(-1)
        # 在最后的轴上，被遮盖的元素使用一个非常大的负值替换，从而其 softmax (指数)输出为 0
        X = d2l.sequence_mask(X.reshape(-1, shape[-1]), valid_lens,
                              value=-1e6)
        return nn.functional.softmax(X.reshape(shape), dim=-1)


```

```
# 考虑由两个 2 × 4 矩阵表示的样本组成的小批量数据集，其中这两个样本的有效长度分别为 2 和 3。
# 经过掩码 softmax 操作，超出有效长度的值都被遮盖为零。
masked_softmax(torch.rand(2, 2, 4), torch.tensor([2, 3]))


```

```
tensor([[[0.3966, 0.6034, 0.0000, 0.0000],
         [0.4718, 0.5282, 0.0000, 0.0000]],

        [[0.4841, 0.2792, 0.2368, 0.0000],
         [0.4889, 0.2826, 0.2285, 0.0000]]])


```

```
# 同样，我们也可以使用二维张量为每个矩阵示例中的每一行指定有效长度。
masked_softmax(torch.rand(2, 2, 4), torch.tensor([[1, 3], [2, 4]]))


```

```
tensor([[[1.0000, 0.0000, 0.0000, 0.0000],
         [0.4509, 0.2201, 0.3290, 0.0000]],

        [[0.5237, 0.4763, 0.0000, 0.0000],
         [0.1962, 0.4115, 0.2280, 0.1643]]])


```

可加性注意力
------

![](https://img-blog.csdnimg.cn/d3c90f3babfa4d10bbdf1bdb7503792c.png)  
![](https://img-blog.csdnimg.cn/930d08dc24e44e9e8936b345bd86dfc0.png)  
好处是 qkv 可以不一样，可以是任意长度

在设计可加性注意力层之前，我们先准备一些需要用到的函数

然后开始生成可加性注意力层：

```
class AdditiveAttention(nn.Module):
    """可加性注意力"""
    def __init__(self, key_size, query_size, num_hiddens, dropout, **kwargs):
        super(AdditiveAttention, self).__init__(**kwargs)
        self.W_k = nn.Linear(key_size, num_hiddens, bias=False)
        self.W_q = nn.Linear(query_size, num_hiddens, bias=False)
        self.w_v = nn.Linear(num_hiddens, 1, bias=False)
        self.dropout = nn.Dropout(dropout)

    def forward(self, queries, keys, values, valid_lens):
        queries, keys = self.W_q(queries), self.W_k(keys)
        # 在维度扩展后，
        # `queries` 的形状：(`batch_size`, 查询的个数, 1, `num_hidden`)
        # `key` 的形状：(`batch_size`, 1, “键－值”对的个数, `num_hiddens`)
        # 使用广播方式进行求和=>feature的形状（batch_size，query个数，key-alue对个数，num_hiddens）
        features = queries.unsqueeze(2) + keys.unsqueeze(1) # 将特征增加一个维度
        features = torch.tanh(features)
        # `self.w_v` 仅有一个输出，因此从形状中移除最后那个维度。
        # `scores` 的形状：(`batch_size`, 查询的个数, “键-值”对的个数)
        scores = self.w_v(features).squeeze(-1)
        self.attention_weights = masked_softmax(scores, valid_lens)
        # `values` 的形状：(`batch_size`, “键－值”对的个数, 值的维度)
        return torch.bmm(self.dropout(self.attention_weights), values)


```

![](https://img-blog.csdnimg.cn/b6f457a28dee491ba871fec4aa116b57.png)

```
queries, keys = torch.normal(0, 1, (2, 1, 20)), torch.ones((2, 10, 2))
# `values` 的小批量数据集中，两个值矩阵是相同的
values = torch.arange(40, dtype=torch.float32).reshape(1, 10, 4).repeat(2, 1, 1)
valid_lens = torch.tensor([2, 6])

attention = AdditiveAttention(key_size=2, query_size=20, num_hiddens=8,
                              dropout=0.1)
attention.eval()
print("queries:",queries.shape)
print("keys:",keys.shape)
print("values:",values.shape)
attention(queries, keys, values, valid_lens)


```

```
queries: torch.Size([2, 1, 20])
keys: torch.Size([2, 10, 2])
values: torch.Size([2, 10, 4])

tensor([[[ 2.0000,  3.0000,  4.0000,  5.0000]],   
        [[10.0000, 11.0000, 12.0000, 13.0000]]], grad_fn=<BmmBackward0>)


```

缩放的 “点－积” 注意力
-------------

使用 “点－积” 可以得到计算效率更高的评分函数。但是 **“点－积”操作要求查询和键具有相同的矢量长度 d 。**

![](https://img-blog.csdnimg.cn/f440a0ab59224a808104ba457ce2cf02.png)![](https://img-blog.csdnimg.cn/0e7d1c9a84f44f9782aff1a655a10338.png)

使用注意力机制的 seq2seq
================

![](https://img-blog.csdnimg.cn/f550731a47874d528adf5719bb895528.png)

1.  **s2s 只传了最后的隐藏状态过去**，当然你也可以说最后的隐藏的状态以及有了之前的信息，但是你需要从这里还原出来位置的信息，所以动机是翻译对应的词的时候，我的注意力关注在**原句子对应的部分**
    
2.  输出作为 quary 是因为假设 RNN 的输出都是在一个语义空间里面，所以用输出不用 embedding 的输入，因为 key value 也是 RNN 的输出，key 和 quary 匹配的时候最好也用 RNN 的输出，这样差不多在一个同样的语义空间里面
    
3.  这样作为上下文的输出和输入的 embedding 合并进入到 RNN  
    ![](https://img-blog.csdnimg.cn/a99204dd0bc14c2482ebb95507a75416.png)  
    ![](https://img-blog.csdnimg.cn/3fa64126d91f4fca98f09cf566915e35.png)
    

自注意力和位置编码
=========

自注意力
----

![](https://img-blog.csdnimg.cn/81537cd9f9e34ccf9d44d5137254f613.png)  
你可以认为，我给定一个序列，其实有点像 RNN，qkv 是一个东西的情况下可以用自注意力这种东西来处理序列，不需要之前一定要有 encoder-decoder,qkv 都是来自于自己  
![](https://img-blog.csdnimg.cn/811f0cf9e80542d08fb10ac6f86a66a9.png)

位置编码
----

不是吧位置信息加到模型里面，不要改变注意力机制本身  
![](https://img-blog.csdnimg.cn/9565bdf1feda4ea489edfb9eb4391ad2.png)  
![](https://img-blog.csdnimg.cn/431f401174b641a1a31be82c2e152c74.png)

```
class PositionalEncoding(nn.Module):
    def __init__(self, num_hiddens, dropout, max_len=1000):
        super(PositionalEncoding, self).__init__()
        self.dropout = nn.Dropout(dropout)
        # Create a long enough `P`
        self.P = torch.zeros((1, max_len, num_hiddens))
        X = torch.arange(max_len, dtype=torch.float32).reshape(
            -1, 1) / torch.pow(
                10000,
                torch.arange(0, num_hiddens, 2, dtype=torch.float32) /
                num_hiddens)
        self.P[:, :, 0::2] = torch.sin(X)
        self.P[:, :, 1::2] = torch.cos(X)

    def forward(self, X):
        X = X + self.P[:, :X.shape[1], :].to(X.device)
        return self.dropout(X)


```

最后使用一个 dropout 来避免模型对位置编码过于敏感  
![](https://img-blog.csdnimg.cn/2430d1238af74118a97f045872c9a55f.png)

```
encoding_dim, num_steps = 32, 60
pos_encoding = PositionalEncoding(encoding_dim, 0)
pos_encoding.eval()
X = pos_encoding(torch.zeros((1, num_steps, encoding_dim)))
P = pos_encoding.P[:, :X.shape[1], :]
d2l.plot(torch.arange(num_steps), P[0, :, 6:10].T, xlabel='Row (position)',
         figsize=(6, 2.5), legend=["Col %d" % d for d in torch.arange(6, 10)])


```

![](https://img-blog.csdnimg.cn/5bd061dad2a646fcb2baa946ea3a87f4.png)  
使用 sin cos 的好处是他编码的是相对的位置信息，可以通过一个线性变换 W 来给你找出来，这样鼓励  
![](https://img-blog.csdnimg.cn/bf691c7d73dd43339d995f4c3f08873c.png)  
![](https://img-blog.csdnimg.cn/cd7df714ae244dac8487ddba9485b521.png)

Transformer
===========

1.transformer 架构
----------------

![](https://img-blog.csdnimg.cn/194fd7a4876c4dcd937e41387a8702b3.png)

2. 多头注意力
--------

![](https://img-blog.csdnimg.cn/1ba27710e0124881a001f962ce0440cf.png)  
多头有点像卷积里面的多通道，但是这里已经有多通道了，所以叫 multi-head

![](https://img-blog.csdnimg.cn/2e0e4fa57e6f42c8ae9bdf42ff9a9358.png)

3. 有掩码的多头注意力
------------

![](https://img-blog.csdnimg.cn/d18040fa46674463b5404b42576633d5.png)  
**编码可以看之后的，解码不行**

4. 基于位置的前馈网络
------------

![](https://img-blog.csdnimg.cn/40d5adaf58c64d7fa6ac86cbdac460ee.png)

5. 层归一化
-------

![](https://img-blog.csdnimg.cn/389effeb3eb34478b83661c391860e17.png)

BN 需要序列长度一致，导致不稳定；**训练和预测的长度本来就不一样，预测会变得越来越长**

6. 信息传递
-------

![](https://img-blog.csdnimg.cn/27e3ebde2778484a82c6ecef00080dac.png)

7. 预测
-----

![](https://img-blog.csdnimg.cn/38133d33a6cf4dee812549deac01da7a.png)

总结
--

![](https://img-blog.csdnimg.cn/a3d3bb02e627419c9bb934eb605e26fa.png)

QA
--

1.  多头注意力，concat 和相加取平均怎么选择？  
    老师认为 concat 保留的信息更全面，更好
2.  为什么在获取词向量之后，需要对词向量进行缩放（乘以 embedding size 的开方之后再加上 PE）  
    embedding 之后，向量长度变长，元素值变小，乘以之后可以保证在 - 1，1 之间，和 position 大小差不多
3.  num of head 是什么？  
    类似卷积的多通道，多个 attention 关注的是不同的特征

BERT
====

![](https://img-blog.csdnimg.cn/4358127680e741f9b2e4fb1a380dfa54.png)  
![](https://img-blog.csdnimg.cn/80def2754cac44bbaf5a47a5934a0f3c.png)  
使得预训练模型足够好，抓住足够多的语义信息  
![](https://img-blog.csdnimg.cn/08b6d787f2aa48a98b889c28358e7115.png)

优化算法
====

![](https://img-blog.csdnimg.cn/2f45f6bb119f4aec85efc0885ffa431c.png)  
![](https://img-blog.csdnimg.cn/79030408dce646678f22cc87ef68226f.png)  
迭代法找到局部最小，当然凸优化是特例

凸集：一个集合任意找两个点，两个点的连线都在这个集合里面  
凸函数：函数上随便取两个点，保证整个函数在两点连线下面  
![](https://img-blog.csdnimg.cn/765f11378a114ac4840cef6d8739cc06.png)  
![](https://img-blog.csdnimg.cn/8efaa6c7f8724adeafde793098e3f0af.png)  
![](https://img-blog.csdnimg.cn/9c6ac5b6453c41cea2902bd2baa45a19.png)

1.  包括一个隐藏层的 MLP，因为他的激活函数是非线性的，非线性是非凸的
2.  卷积本身是线性，但是加了激活函数就不是了

凸函数的表达能力是非常有限的，优化大多是凸的

![](https://img-blog.csdnimg.cn/469210e92aff4d079f3f4683cf6fa455.png)  
![](https://img-blog.csdnimg.cn/8d54ecbcbe004af4a57d29d2d6a931e4.png)  
导数是线性可加的

![](https://img-blog.csdnimg.cn/b16dff549dc349a395c2d1f4d649fc6a.png)  
在方向上的抖动没那么严重，降低了方差

![](https://img-blog.csdnimg.cn/b54af9d15ad04e56b4ec1e3be8e55b5a.png)  
loss 平面比较复杂比较陡的时候，平滑的改变方向（SGD，0.9）

![](https://img-blog.csdnimg.cn/ad33fd9f6d8b49cb96b00a106929976e.png)

Adam 对学习率没有那么敏感，做了非常多的平滑（可以认为是一个非常非常平滑的 SGD）

![](https://img-blog.csdnimg.cn/c152d77e9ba34c35b9cd2a110ecd62cf.png)  
![](https://img-blog.csdnimg.cn/5ad7d329a737433f973d83dde29a4413.png)